{"version":3,"sources":["webpack:///./src/pages/infrastructure/devops-continuous-delivery/index.mdx"],"names":["name","_frontmatter","PageDescription","props","console","warn","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","mdxType","parentName","isMDXComponent"],"mappings":"8LAUsBA,E,4DAFTC,G,UAAe,IAOtBC,GALgBF,EAKgB,kBALR,SAA6BG,GAEzD,OADAC,QAAQC,KAAK,aAAeL,EAAO,2EAC5B,kBAASG,KAIZG,EAAc,CAClBL,gBAEIM,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGP,EACF,8BACD,OAAO,YAACI,EAAD,eAAeD,EAAiBH,EAAhC,CAAuCO,WAAYA,EAAYC,QAAQ,cAG5E,YAACT,EAAD,CAAiBS,QAAQ,mBAAzB,gLACyK,iDADzK,4DAGA,kCACA,4BAAW,iBAAGC,WAAW,IACrB,KAAQ,4DADD,wCAAX,kFAEoI,iBAAGA,WAAW,IAC9I,KAAQ,uCADwH,kBAFpI,sEAIkG,iBAAGA,WAAW,IAC5G,KAAQ,oCADsF,cAJlG,gGAMwH,0BAAYA,WAAW,KAAvB,sCANxH,UAOA,4BAAW,iBAAGA,WAAW,IACrB,KAAQ,4CADD,mBAAX,yMAEsO,iBAAGA,WAAW,IAChP,KAAQ,yBAD0N,aAFtO,gDAIuE,0BAAYA,WAAW,KAAvB,mBAJvE,+IAKA,4BAAW,iBAAGA,WAAW,IACrB,KAAQ,wBADD,qCAAX,KAEoD,kBAAIA,WAAW,KAAf,6BAFpD,kXAGA,6CACA,uHAAsG,iBAAGA,WAAW,IAChH,KAAQ,uCAD0F,UAAtG,0BAE8C,iBAAGA,WAAW,IACxD,KAAQ,4FADkC,wBAF9C,mJAQA,oJAAmI,iBAAGA,WAAW,IAC7I,KAAQ,6CADuH,kBAAnI,yHAEqJ,iBAAGA,WAAW,IAC/J,KAAQ,uBADyI,sBAFrJ,oBAOA,4CACA,+FAA8E,kBAAIA,WAAW,KAAf,kCAA9E,WAAoJ,iBAAGA,WAAW,IAC9J,KAAQ,6DADwI,0BAApJ,4cAGA,oBACE,UAAa,4BACb,MAAS,CACP,SAAY,WACZ,QAAW,QACX,WAAc,OACd,YAAe,OACf,SAAY,UAPhB,WAUI,oBAAMA,WAAW,OACjB,UAAa,qCACb,MAAS,CACP,cAAiB,qBACjB,SAAY,WACZ,OAAU,IACV,KAAQ,IACR,gBAAmB,goBACnB,eAAkB,QAClB,QAAW,WAnBjB,OAsBA,mBAAKA,WAAW,OACZ,UAAa,0BACb,IAAO,UACP,MAAS,UACT,IAAO,0EACP,OAAU,CAAC,+EAAgF,+EAAgF,gFAC3K,MAAS,kCACT,MAAS,CACP,MAAS,OACT,OAAU,OACV,OAAU,IACV,cAAiB,SACjB,SAAY,WACZ,IAAO,IACP,KAAQ,KAEV,QAAW,SAtCf,UAyCA,4JAA2I,iBAAGA,WAAW,IACrJ,KAAQ,4GACP,0BAAYA,WAAW,KAAvB,uBAFL,QAEgF,iBAAGA,WAAW,IAC1F,KAAQ,uHACP,0BAAYA,WAAW,KAAvB,2BAJL,oHAIgM,0BAAYA,WAAW,KAAvB,eAJhM,oCAI4R,iBAAGA,WAAW,IACtS,KAAQ,wFADgR,qBAJ5R,gHAM+I,iBAAGA,WAAW,IACzJ,KAAQ,6CADmI,uBAN/I,4BASA,+QAA8P,kBAAIA,WAAW,KAAf,kCAA9P,kVACA,oBACE,UAAa,4BACb,MAAS,CACP,SAAY,WACZ,QAAW,QACX,WAAc,OACd,YAAe,OACf,SAAY,UAPhB,WAUI,oBAAMA,WAAW,OACjB,UAAa,qCACb,MAAS,CACP,cAAiB,sBACjB,SAAY,WACZ,OAAU,IACV,KAAQ,IACR,gBAAmB,gwBACnB,eAAkB,QAClB,QAAW,WAnBjB,OAsBA,mBAAKA,WAAW,OACZ,UAAa,0BACb,IAAO,iCACP,MAAS,iCACT,IAAO,4FACP,OAAU,CAAC,iGAAkG,iGAAkG,kGAC/M,MAAS,kCACT,MAAS,CACP,MAAS,OACT,OAAU,OACV,OAAU,IACV,cAAiB,SACjB,SAAY,WACZ,IAAO,IACP,KAAQ,KAEV,QAAW,SAtCf,UAyCA,6QACA,8DACA,uCACA,sBACE,kBAAIA,WAAW,MAAf,+OACA,kBAAIA,WAAW,MAAf,2FAAgH,sBAAQA,WAAW,MAAnB,cAAhH,IAAoK,iBAAGA,WAAW,KAC9K,KAAQ,oDADwJ,mCAItK,oDACA,oBACE,UAAa,4BACb,MAAS,CACP,SAAY,WACZ,QAAW,QACX,WAAc,OACd,YAAe,OACf,SAAY,UAPhB,WAUI,oBAAMA,WAAW,OACjB,UAAa,qCACb,MAAS,CACP,cAAiB,sBACjB,SAAY,WACZ,OAAU,IACV,KAAQ,IACR,gBAAmB,opBACnB,eAAkB,QAClB,QAAW,WAnBjB,OAsBA,mBAAKA,WAAW,OACZ,UAAa,0BACb,IAAO,+BACP,MAAS,+BACT,IAAO,6FACP,OAAU,CAAC,kGAAmG,kGAAmG,mGACjN,MAAS,kCACT,MAAS,CACP,MAAS,OACT,OAAU,OACV,OAAU,IACV,cAAiB,SACjB,SAAY,WACZ,IAAO,IACP,KAAQ,KAEV,QAAW,SAtCf,UAyCA,sBACE,kBAAIA,WAAW,MAAf,6DAAkF,0BAAYA,WAAW,MAAvB,UAAlF,6CAAmL,0BAAYA,WAAW,MAAvB,gEAAnL,KACA,kBAAIA,WAAW,MAAf,iHAAsI,sBAAQA,WAAW,MAAnB,mBAAtI,KACA,kBAAIA,WAAW,MAAf,0CAA+D,0BAAYA,WAAW,MAAvB,OAA/D,0DAA0K,sBAAQA,WAAW,MAAnB,UAA1K,IACE,kBAAIA,WAAW,MACb,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,qBAApB,IAA+E,0BAAYA,WAAW,MAAvB,mBAC/E,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,YAApB,WAA6E,0BAAYA,WAAW,MAAvB,WAA7E,uBACA,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,gBAApB,WAAiF,0BAAYA,WAAW,MAAvB,aAAjF,uBACA,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,mBAApB,IAA6E,0BAAYA,WAAW,MAAvB,oEAC7E,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,SAApB,IAAmE,0BAAYA,WAAW,MAAvB,qBACnE,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,YAApB,WAA6E,0BAAYA,WAAW,MAAvB,+CAA7E,IAA0K,kBAAIA,WAAW,MAAf,gCAC1K,kBAAIA,WAAW,MAAK,sBAAQA,WAAW,MAAnB,cAApB,kCACA,kBAAIA,WAAW,MAAf,aAAkC,sBAAQA,WAAW,MAAnB,aAAlC,6BAA8G,sBAAQA,WAAW,MAAnB,gBAGlH,kBAAIA,WAAW,MAAf,mPACA,kBAAIA,WAAW,MAAf,4HAEF,uBAAK,oBAAMA,WAAW,MAClB,UAAa,kBADZ,uBAIL,0DACA,8OAA6N,iBAAGA,WAAW,IACvO,KAAQ,uDADiN,+BAA7N,qCAE8E,iBAAGA,WAAW,IACxF,KAAQ,wDADkE,cAF9E,gDA0DA,oCACA,qBAAG,kBAAIA,WAAW,KAAf,4FAAH,6BAAqJ,iBAAGA,WAAW,IAC/J,KAAQ,2CADyI,qBAArJ,mCAOJH,EAAWI,gBAAiB","file":"component---src-pages-infrastructure-devops-continuous-delivery-index-mdx-effb4423cea8c351ae72.js","sourcesContent":["import * as React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\n\nimport DefaultLayout from \"/home/runner/work/refarch-kc/refarch-kc/docs/node_modules/gatsby-theme-carbon/src/templates/Default.js\";\nexport const _frontmatter = {};\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n  return <div {...props} />;\n};\n\nconst PageDescription = makeShortcode(\"PageDescription\");\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <PageDescription mdxType=\"PageDescription\">\nThe implemented DevOps pipelines for the Reefer Container Shipment solution reference implementation of the Event-Driven Reference Architecture. This chapter focuses on the <strong>Continuous Delivery</strong> capability implemented in the reference implementation.\n    </PageDescription>\n    <h1>{`Overview`}</h1>\n    <p>{`Our `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/infrastructure/devops-continuous-integration\"\n      }}>{`Continuous Integration (CI) approach`}</a>{` is one of “zero-infrastructure overhead”. To accomplish this goal, we utilize `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/features/actions\"\n      }}>{`GitHub Actions`}</a>{` to build and push a microservice’s associated container images to `}<a parentName=\"p\" {...{\n        \"href\": \"https://hub.docker.com/u/ibmcase\"\n      }}>{`Docker Hub`}</a>{` for public consumption. The GitHub Actions workflows are defined in the owning repository’s `}<inlineCode parentName=\"p\">{`.github/workflows/dockerbuild.yaml`}</inlineCode>{` file.`}</p>\n    <p>{`Our `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/infrastructure/devops-gitops\"\n      }}>{`GitOps approach`}</a>{` focuses on a single-repository, environment-per-subdirectory model which can be forked and cloned to replicate deployments to other clusters and environments. The reference implementation utilizes `}<a parentName=\"p\" {...{\n        \"href\": \"https://kustomize.io/\"\n      }}>{`Kustomize`}</a>{` as its templating technology to utilize the `}<inlineCode parentName=\"p\">{`app-deploy.yaml`}</inlineCode>{` files, provided by each individual microservice, as a base and then layer in environment-specific configuration and credentials as needed.`}</p>\n    <p>{`Our `}<a parentName=\"p\" {...{\n        \"href\": \"#continuous-delivery\"\n      }}>{`Continuous Delivery (CD) approach`}</a>{`, `}<em parentName=\"p\">{`the topic of this chapter`}</em>{`, focuses on a GitOps-based delivery model, using a GitHub repository as a single source of truth for the deployment, management, and operations of our running application components. In this model, we have the flexibility to use multiple open-source technologies to apply the single source of truth from a given GitHub repository onto a desired cluster environment.`}</p>\n    <h1>{`Continuous delivery`}</h1>\n    <p>{`One of the main tools used in this space is a GitOps-focused continuous delivery project named `}<a parentName=\"p\" {...{\n        \"href\": \"https://argoproj.github.io/argo-cd/\"\n      }}>{`ArgoCD`}</a>{`. As documented by the `}<a parentName=\"p\" {...{\n        \"href\": \"https://ibm-garage-cloud.github.io/ibm-garage-developer-guide/guides/continuous-delivery\"\n      }}>{`IBM Garage for Cloud`}</a>{` team, ArgoCD can monitor GitHub-based projects and apply changes stored in that repository’s YAML files to a running Kubernetes-based cluster.`}</p>\n    {\n      /* Another DevOps tool which provides the opportunity to deployment applications via the GitOps methodology is [Tekton](https://tekton.dev/). The Tekton Pipelines project provides a declarative language for defining and executing both CI and CD-style pipelines, all defined with common Kubernetes-like nomenclature. It even has the capability to kick off pipeline runs based off of GitHub webhooks. */\n    }\n    <p>{`We have documented our general GitOps strategy & methodology for generation of deployment source configuration files in the `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/infrastructure/devops-gitops/\"\n      }}>{`GitOps chapter`}</a>{` of this manual, while the details of our ArgoCD-based deployments of those GitOps-based artifacts are covered in the `}<a parentName=\"p\" {...{\n        \"href\": \"#argocd-deployments\"\n      }}>{`ArgoCD deployments`}</a>{` section below. `}{\n        /* and the details of our Tekton-based deployments are covered in the [Tekton deployments](#tekton-deployments) section below.*/\n      }</p>\n    <h2>{`ArgoCD deployments`}</h2>\n    <p>{`Our main continuous delivery pattern operates on the same principle of `}<em parentName=\"p\">{`“zero-infrastructure overhead”`}</em>{` as our `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/infrastructure/devops-continuous-integration/\"\n      }}>{`continuous integration`}</a>{` implementations. This allows us to be agile, adaptable, and efficient in what we deploy where.  ArgoCD is a perfect companion to this principle, as we do not need additional long-running CD infrastructure to monitor either a source environment or a target deployment environment. Our CI process sits with our code (on the same hosted infrastructure), while our CD process sits with the target deployment environment (on the same Kubernetes-based cluster).`}</p>\n    <span {...{\n      \"className\": \"gatsby-resp-image-wrapper\",\n      \"style\": {\n        \"position\": \"relative\",\n        \"display\": \"block\",\n        \"marginLeft\": \"auto\",\n        \"marginRight\": \"auto\",\n        \"maxWidth\": \"715px\"\n      }\n    }}>{`\n      `}<span parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-background-image\",\n        \"style\": {\n          \"paddingBottom\": \"43.05555555555555%\",\n          \"position\": \"relative\",\n          \"bottom\": \"0\",\n          \"left\": \"0\",\n          \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAhOAAAITgGMMQDsAAABeUlEQVQoz21Sy07DMBDMl/JTCHGAAyckDtzKNwAqB24VFBXUZ0qS5mnH72HttEkLrGLZ2bVnZseOrHOgj4aDUgo+WqFwfnGJoqxQ1g3i7xR1w2GtwxDH6+68j6grOAipsN4mKLlCqx1mX3M0TYOcQDfJjkhEOFS0FvcTQUNitY4xnX5gm6Q9aDT+ZJhnMiS4BoS2gcDT8LZFxQRqoaG1CQd8PWk04kpi8vaOx+cxFsvVAHh2NcPtUxYSQlloY/o2GOOoufjTmrMGSnDkFSMyc9ryy6zCOhd90tu0K0psqP2WFHNpgh2SFGrTESrjAlCcZKRcD0ReoTMSnLPgVUUX4ONhNMLdzXVYN4wFIKm6lr0XXpQmZmsHoENEiphVYDcw+3YLUpilKVmgyUcZwIztwGopkZCvjv7V3tcThfgVlmidsWFtbDcrAt4VBSSBL6oMr5slbUSw4RgwKDwg9wXyRNBz8Js5vUchNRgBpXmJhi7Iq/UELeXVP4A/h8q6fVY9Pw0AAAAASUVORK5CYII=')\",\n          \"backgroundSize\": \"cover\",\n          \"display\": \"block\"\n        }\n      }}></span>{`\n  `}<img parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-image\",\n        \"alt\": \"Argo CD\",\n        \"title\": \"Argo CD\",\n        \"src\": \"/refarch-kc/static/8c949d63864e30205b95ccd452a6cde1/8895e/argocd-cd.png\",\n        \"srcSet\": [\"/refarch-kc/static/8c949d63864e30205b95ccd452a6cde1/7fc1e/argocd-cd.png 288w\", \"/refarch-kc/static/8c949d63864e30205b95ccd452a6cde1/a5df1/argocd-cd.png 576w\", \"/refarch-kc/static/8c949d63864e30205b95ccd452a6cde1/8895e/argocd-cd.png 715w\"],\n        \"sizes\": \"(max-width: 715px) 100vw, 715px\",\n        \"style\": {\n          \"width\": \"100%\",\n          \"height\": \"100%\",\n          \"margin\": \"0\",\n          \"verticalAlign\": \"middle\",\n          \"position\": \"absolute\",\n          \"top\": \"0\",\n          \"left\": \"0\"\n        },\n        \"loading\": \"lazy\"\n      }}></img>{`\n    `}</span>\n    <p>{`To utilize ArgoCD in this manner, we leverage the Appsody-based, Kustomize-extended Kubernetes YAML files that define the necessary `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/appsody/appsody-operator/blob/master/doc/user-guide.md#custom-resource-definition-crd\"\n      }}><inlineCode parentName=\"a\">{`AppsodyApplication`}</inlineCode></a>{` and `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/OpenLiberty/open-liberty-operator/blob/master/doc/user-guide.adoc#custom-resource-definition-crd\"\n      }}><inlineCode parentName=\"a\">{`OpenLibertyApplication`}</inlineCode></a>{` custom resources our application’s microservices require. ArgoCD will handle deploying the entirety of a single `}<inlineCode parentName=\"p\">{`environment`}</inlineCode>{` subdirectory, as defined in the `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/ibm-cloud-architecture/refarch-kc-gitops/tree/master/environments\"\n      }}>{`GitOps repository`}</a>{`. For details on how the environments subdirectory and its component files are structured, refer to the peer `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/infrastructure/devops-gitops/\"\n      }}>{`GitOps Environments`}</a>{` chapter of this manual.`}</p>\n    <p>{`An ArgoCD application is created on the ArgoCD server inside the target environment that can read from the GitOps repository. ArgoCD can also deploy between clusters, which does come in handy in certain use cases, but remember our squad’s goal of `}<em parentName=\"p\">{`“zero-infrastructure overhead”`}</em>{`, so we deploy from ArgoCD into the same cluster it is deployed on the majority of the time. The ArgoCD application is a Custom Resource Definition, comprising of the details necessary to determine the remote code repository URL, the branch of the code to use, the target namespace, and any formatting capabilities that are necessary.`}</p>\n    <span {...{\n      \"className\": \"gatsby-resp-image-wrapper\",\n      \"style\": {\n        \"position\": \"relative\",\n        \"display\": \"block\",\n        \"marginLeft\": \"auto\",\n        \"marginRight\": \"auto\",\n        \"maxWidth\": \"816px\"\n      }\n    }}>{`\n      `}<span parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-background-image\",\n        \"style\": {\n          \"paddingBottom\": \"54.166666666666664%\",\n          \"position\": \"relative\",\n          \"bottom\": \"0\",\n          \"left\": \"0\",\n          \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2UlEQVQoz32Ty4/TMBDG+/8fgS0t4iEhDhxWSBwQR25c0CKB4LDNs0mclxMndtKkEW0/ZqxtCcsj0siSZ/zzN54vi/V6BS/JIbISZd0gjFN42wR+JBDwShHEAm4YoWpanE4nHA6HSxyPR+zGEbXpUWuDxcOrJQJRQFYKstX46vpwgghxmuPGcbAhWC5rC21Nh799DOVvmiYsHj1eY38AqtZAdTvkSqMxOwyUNMOIjefj5ss35FWDphuorkOlO1Izj96GbDQWD5YrRLLFbZTBSQo4cYGkVKiMwTDusSHFHz5+wncvhitKm7d192IT5wgzScCrFYTq4NKmn0paSwjZkBIN07PSH0gqjYBy/n/Co8uioqY3pJZFbWbAAjElSgLuSGHbD7aY4z7gD2BOwOWTp0jugLx5Bkqa6LCf0I8TgkxeoHP4HHoBrp+9oJZ+B0Z5hbRW0DQkTQrPh7jtIKv+3TIDn798dQGehyJoKKXW1l/dbrSKW/IZv2lHk9/SQa53rYBfqi3w9fUbbIsGPm/apKQDFRLyXkkWKii4UJE92IcNgfnx2QlCKqRkp5DqGWyH8vbde3y+DZHRX2JIDXuMi3PVQtFhRZ7009L6lBW29AwM4Bq+jH07B/4EvT8r67gG2T4AAAAASUVORK5CYII=')\",\n          \"backgroundSize\": \"cover\",\n          \"display\": \"block\"\n        }\n      }}></span>{`\n  `}<img parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-image\",\n        \"alt\": \"Argo CD - Application Topology\",\n        \"title\": \"Argo CD - Application Topology\",\n        \"src\": \"/refarch-kc/static/b2187a68ccb8098332ff7e6aaef991ef/cd0dd/argocd-application-topology.png\",\n        \"srcSet\": [\"/refarch-kc/static/b2187a68ccb8098332ff7e6aaef991ef/7fc1e/argocd-application-topology.png 288w\", \"/refarch-kc/static/b2187a68ccb8098332ff7e6aaef991ef/a5df1/argocd-application-topology.png 576w\", \"/refarch-kc/static/b2187a68ccb8098332ff7e6aaef991ef/cd0dd/argocd-application-topology.png 816w\"],\n        \"sizes\": \"(max-width: 816px) 100vw, 816px\",\n        \"style\": {\n          \"width\": \"100%\",\n          \"height\": \"100%\",\n          \"margin\": \"0\",\n          \"verticalAlign\": \"middle\",\n          \"position\": \"absolute\",\n          \"top\": \"0\",\n          \"left\": \"0\"\n        },\n        \"loading\": \"lazy\"\n      }}></img>{`\n    `}</span>\n    <p>{`ArgoCD then handles automatically (or manually) syncing and applying the deployments into the target namespace with the state that is described in the Kustomized YAMLs from the desired environment’s subdirectory in the remote GitOps repository.`}</p>\n    <h3>{`Deploying a microservice with ArgoCD`}</h3>\n    <h4>{`Prerequisites`}</h4>\n    <ol>\n      <li parentName=\"ol\">{`Ensure all necessary Kubernetes ConfigMaps and Secrets have been created in the namespace in which the application will be running. This may vary depending upon your level of exposure to the public Internet, as well as cluster tenancy.`}</li>\n      <li parentName=\"ol\">{`Ensure ArgoCD has been deployed to the local cluster with connectivity to the Internet. `}<strong parentName=\"li\">{`Reference:`}</strong>{` `}<a parentName=\"li\" {...{\n          \"href\": \"https://github.com/argoproj-labs/argocd-operator\"\n        }}>{`ArgoCD Operator Documentation`}</a></li>\n    </ol>\n    <h4>{`Using the ArgoCD dashboard`}</h4>\n    <span {...{\n      \"className\": \"gatsby-resp-image-wrapper\",\n      \"style\": {\n        \"position\": \"relative\",\n        \"display\": \"block\",\n        \"marginLeft\": \"auto\",\n        \"marginRight\": \"auto\",\n        \"maxWidth\": \"812px\"\n      }\n    }}>{`\n      `}<span parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-background-image\",\n        \"style\": {\n          \"paddingBottom\": \"54.513888888888886%\",\n          \"position\": \"relative\",\n          \"bottom\": \"0\",\n          \"left\": \"0\",\n          \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiUlEQVQoz5WSSUvDUBSF818FC21tqQO6EBER/4AbF6Io4oCoadLGTgqaiuBCEOla6KbSam2bqS/T8b7XgQpK6oXDI+Tmyzn3XSmZiOPw+Ay7+wfQiiU8Pr+i9lZH86uLZrsTqRbp/aONeqOJRusT0sxsDHtHp9je2cWVqsEPQvi+jzAMIxWQeHUNE08vNTSaLUixeAKlcgWFwjX06gMMy4ZlWYOPgmAKcICA+gS4Z0BKptJQ8xoURcG9XoXTZ9Tgi6b/aAxMzKWg5jRks1kBtJw+GGNTRZ4Ur87IoayokGVZAG0CWrb9Y47TOORIw7QgpTPzKJbK0DRNAHt2X8TmQM/zxBlZQ4cmzV/KLCyiXLkhYB53ug7DYRTZBXMHcl0PHodHyCeXwuHS8oq4ZS0/ANrkzvV4UzAWf2YEZt4fone8p8eBq2vrw8h5sTaW7cA0TTiOQ/Mk0TxdchqKZL/vYjgZeWNzC5dKDifnFyhUbsVf2p2uWNZOzxQ3x3eTO+cbMJI9PF1yOAn8Bg3rMl2WZCOMAAAAAElFTkSuQmCC')\",\n          \"backgroundSize\": \"cover\",\n          \"display\": \"block\"\n        }\n      }}></span>{`\n  `}<img parentName=\"span\" {...{\n        \"className\": \"gatsby-resp-image-image\",\n        \"alt\": \"Argo CD - Create Application\",\n        \"title\": \"Argo CD - Create Application\",\n        \"src\": \"/refarch-kc/static/7d169f2dfade05e6e380c5fdf59a8d77/155f7/argocd-create-application-ui.png\",\n        \"srcSet\": [\"/refarch-kc/static/7d169f2dfade05e6e380c5fdf59a8d77/7fc1e/argocd-create-application-ui.png 288w\", \"/refarch-kc/static/7d169f2dfade05e6e380c5fdf59a8d77/a5df1/argocd-create-application-ui.png 576w\", \"/refarch-kc/static/7d169f2dfade05e6e380c5fdf59a8d77/155f7/argocd-create-application-ui.png 812w\"],\n        \"sizes\": \"(max-width: 812px) 100vw, 812px\",\n        \"style\": {\n          \"width\": \"100%\",\n          \"height\": \"100%\",\n          \"margin\": \"0\",\n          \"verticalAlign\": \"middle\",\n          \"position\": \"absolute\",\n          \"top\": \"0\",\n          \"left\": \"0\"\n        },\n        \"loading\": \"lazy\"\n      }}></img>{`\n    `}</span>\n    <ol>\n      <li parentName=\"ol\">{`Access the ArgoCD Dashboard via it’s exposed Route in the `}<inlineCode parentName=\"li\">{`argocd`}</inlineCode>{` namespace. This should be in the form of `}<inlineCode parentName=\"li\">{`https://argocd-server-[namespace].apps.[cluster-based-route]`}</inlineCode>{`.`}</li>\n      <li parentName=\"ol\">{`Depending upon your cluster and ArgoCD, you will have specific login credentials. Login as directed and click `}<strong parentName=\"li\">{`NEW APPLICATION`}</strong>{`.`}</li>\n      <li parentName=\"ol\">{`Enter the following parameters for the `}<inlineCode parentName=\"li\">{`dev`}</inlineCode>{` environment of the reference implementation and click `}<strong parentName=\"li\">{`CREATE`}</strong>{`.`}\n        <ul parentName=\"li\">\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Application Name:`}</strong>{` `}<inlineCode parentName=\"li\">{`refarch-kc-dev`}</inlineCode></li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Project:`}</strong>{` Select `}<inlineCode parentName=\"li\">{`default`}</inlineCode>{` from the drop-down`}</li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Sync Policy:`}</strong>{` Select `}<inlineCode parentName=\"li\">{`Automatic`}</inlineCode>{` from the drop-down`}</li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Repository URL:`}</strong>{` `}<inlineCode parentName=\"li\">{`https://github.com/ibm-cloud-architecture/refarch-kc-gitops.git`}</inlineCode></li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Path:`}</strong>{` `}<inlineCode parentName=\"li\">{`environments/dev`}</inlineCode></li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Cluster:`}</strong>{` Select `}<inlineCode parentName=\"li\">{`in-cluster (https://kubernetes.default.svc)`}</inlineCode>{` `}<em parentName=\"li\">{`(this is our local cluster)`}</em></li>\n          <li parentName=\"ul\"><strong parentName=\"li\">{`Namespace:`}</strong>{` Your desired target namespace`}</li>\n          <li parentName=\"ul\">{`Click the `}<strong parentName=\"li\">{`Directory`}</strong>{` section label and select `}<strong parentName=\"li\">{`Kustomize`}</strong></li>\n        </ul>\n      </li>\n      <li parentName=\"ol\">{`Once the application is successfully created inside ArgoCD, you can click the application tile to see the latest status of the ArgoCD-managed, GitOps-deployed microservice instances. It should begin synchronizing immediately upon creation.`}</li>\n      <li parentName=\"ol\">{`As ArgoCD applies the desired configuration to the cluster, you should see the pods of the microservices being created:`}</li>\n    </ol>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-shell\"\n      }}>{`kubectl get Pods\n`}</code></pre>\n    <h4>{`Using the command-line interface`}</h4>\n    <p>{`ArgoCD provides a command-line interface as well, however we are not covering that in this reference implementation. Once you are satisfied with the ArgoCD dashboard-based deployment pattern, you can reference the `}<a parentName=\"p\" {...{\n        \"href\": \"https://argoproj.github.io/argo-cd/getting_started/\"\n      }}>{`ArgoCD Getting Started docs`}</a>{` for further details on using the `}<a parentName=\"p\" {...{\n        \"href\": \"https://argoproj.github.io/argo-cd/cli_installation/\"\n      }}>{`ArgoCD CLI`}</a>{` and CRD YAMLs for programmatic interaction.`}</p>\n    {\n      /*\n      ## Tekton deployments\n      We have also implemented some facets of the project deployment workflows using the [Tekton Pipelines](https://tekton.dev/) project and its inherent ease of support of the [Appsody](https://appsody.dev/) open-source developer experience project through the standard integration between the two built into the [Kabanero](https://kabanero.io/) open-source project, or more formally, the [IBM Cloud Pak for Applications](https://www.ibm.com/cloud/cloud-pak-for-applications).\n      ![Argo CD](images/tekton-cd.png)\n      Defined in the [/scripts/tekton](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/tree/master/scripts/tekton) directory, we have a simple pipeline that will utilize the `appsody deploy` command to deploy the generated **AppsodyApplication** custom resource definition YAML to the target environment. Similar to our ArgoCD-based deployments of Helm-generated, standard Kubernetes YAMLs, AppsodyApplication YAMLs can also be deployed through ArgoCD in a GitOps manner. However, for demonstration inside this project, additional capabilities are provided to showcase how we can utilize different pieces of the platform to deploy similar applications when different requirements are presented. Similar to ArgoCD, Tekton Pipelines run on the same cluster _(and often in the same namespace!)_ as your running application code, thus allowing for more programmatic control over the deployment, management, operations, and existence of your application components.\n      The key artifact that enables Tekton to deploy our Appsody-based `refarch-reefer-ml/simulator` microservice is the generated `app-deploy.yaml` file. The [refarch-reefer-ml/simulator/app-deploy.yaml](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/simulator/app-deploy.yaml) file was generated according to the `appsody build` command and then annotated with the required environment variables and metadata for successful operation in a given namespace, very similar to the pattern required for generating our Helm-templated YAMLs in the [ArgoCD deployments](#argocd-deployments) section above.\n      ![Tekton CD - Dashboard](images/tekton-create-pr.png)\n      We then make use of the [Appsody Operator](https://appsody.dev/docs/using-appsody/building-and-deploying#deployment-via-the-appsody-operator---overview) to apply the AppsodyApplication to the target environment through the `appsody deploy --no-build` command. As documented in the [Appsody Docs](https://appsody.dev/docs/using-appsody/building-and-deploying#deploying-your-application-through-docker-hub), we are able to take advantage of the pre-built container images available on Docker Hub and the annotated `app-deploy.yaml` file that is now a synonymous GitOps-like deployment artifact to quickly apply the change to the target namespace in the same cluster. Once the `appsody deploy` command is succesful, the Appsody Operator and Kubernetes takes care of the rest and reconciles the necessary underlying Kubernetes artifacts that are required to fulfill the requirements of serving up the application code in real-time!\n      ![Tekton CD - PipelineRun Logs](images/tekton-pr-logs.png)\n      ### Deploying the simulator microservice with Tekton & Appsody\n      ### Prerequisites\n      1. Ensure all necessary Kubernetes ConfigMaps and Secrets have been created in the namespace in which the application will be running.\n      2. Ensure an [Appsody Operator](https://appsody.dev/docs/using-appsody/building-and-deploying#deployment-via-the-appsody-operator---overview) has been configured to watch the namespace in which the application will be running.\n      3. Create a new or modify an existing Service Account in the target namespace and bind the required API RBAC requirements for the Appsody Operator.\n         * Further details available in the [Appsody Docs](https://appsody.dev/docs/using-appsody/building-and-deploying#rbac-considerations-for-the-use-of-appsody-deploy-and-appsody-operator-commands)\n         * A sample YAML document has been provided via [rbac-sa.yaml](https://github.com/ibm-cloud-architecture/refarch-reefer-ml/blob/master/scripts/tekton/rbac-sa.yaml), with environment-specific updates to the Namespace and Service Account name fields being required.\n      3. From the `refarch-reefer-ml` directory, import the Tekton pipeline artifacts:\n      ```shell\n      kubectl apply -f scripts/tekton/\n      ```\n      4. Validate these items have been imported successfully by querying the cluster:\n      ```shell\n      kubectl get Pipeline,Task,PipelineResource\n      ```\n      ### Using the command-line interface\n      1. Open the `/scripts/tekton/manual/simulator-pipeline-run.yaml` file in a text editor and ensure everything makes sense.\n      2. Kick off a new pipeline run with the Kubernetes CLI:\n      ```shell\n      kubectl create -f scripts/tekton/manual/simulator-pipeline-run.yaml\n      ```\n      3. You can monitor the pipeline by common `kubectl get` and `kubectl describe` commands:\n      ```shell\n      kubectl get PipelineRun\n      ```\n      For further details on how to access the logs of a PipelineRun, reference the [Tekton Pipelines documentation](https://github.com/tektoncd/pipeline/blob/v0.9.2/docs/logs.md).\n      4. Once the pipeline completes, you should see a deployed instance of the Simulator Appsody application:\n      ```shell\n      kubectl get Pods\n      ```\n      ### Using the Tekton dashboard\n      1. Access the Tekton Pipelines dashboard from your Kabanero installation or directly via the defined Route. This will be something similar to [https://tekton-dashboard-tekton-pipelines.apps.[cluster-based-route]](https://tekton-dashboard-tekton-pipelines.apps.green.ocp.csplab.local).\n      2. Click **PipelineRuns** in the left-nav menu and click **Create PipelineRun** from the upper-right of the page.\n      3. Enter the following parameters and click **Create**:\n         * **Namespace:** Target namespace for application deployment target\n         * **Pipeline:** `appsody-deploy-pipeline`\n         * **PipelineResources > git-source:** `git-source-reefer-ml`\n         * **Params > context:** `simulator`\n         * **Service Account:** `reefer-simulator`\n      4. A new PipelineRun will be created. Click on the name of the running PipelineRun.\n      5. From here, you can monitor the live running logs of the pipeline, as well as see what is running from the command-line with Kubectl (`kubectl get pods`). Note that the pipeline is actually running in pods deployed to the target namespace!\n      */\n    }\n    <h1>{`Next steps`}</h1>\n    <p><em parentName=\"p\">{`Once your ArgoCD-deployed application instances are deployed, synchronized, and running,`}</em>{` you are ready to run the `}<a parentName=\"p\" {...{\n        \"href\": \"/refarch-kc/integration-tests/overview/\"\n      }}>{`Integration Tests`}</a>{` to validate your environment!`}</p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}