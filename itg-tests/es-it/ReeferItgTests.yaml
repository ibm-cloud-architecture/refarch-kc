apiVersion: batch/v1
kind: Job
metadata:
  name: reefer-itgtests-job
spec:
  template:
    metadata:
      name: reefer-itgtests-job
    spec:
      containers:
      - name: ibmcase-python
        image: ibmcase/kcontainer-python:itgtests
        imagePullPolicy: Always
        command:
        - /bin/bash
        - -c
        - |
              # Understand what environment we are executing against
              if [ -z "$KAFKA_USER" ]; then
                KAFKA_ENV="LOCAL"
              elif [ "$KAFKA_USER" == "token" ]; then
                KAFKA_ENV="IBMCLOUD"
              else
                KAFKA_ENV="OCP"
              fi

              # Export KAFKA_ENV since it is used by the test cases
              export KAFKA_ENV=${KAFKA_ENV}

              # Obfuscate KAFKA_PASSWORD
              if [ "`echo -n ${KAFKA_PASSWORD} | wc -c`" -gt 3 ]; then
                FIRST_CH=${KAFKA_PASSWORD:0:1}
                LAST_CH=${KAFKA_PASSWORD: -1}
                OBFUSCATED_PASSWORD="${FIRST_CH}*****${LAST_CH}"
              else
                OBFUSCATED_PASSWORD="*******"
              fi

              echo "-----------------------------------------------------------------"
              echo "-- Reefer Container Shipment EDA application Integration Tests --"
              echo "-----------------------------------------------------------------"
              echo
              echo "Executing integrations tests from branch $BRANCH of $GITHUB_REPO"
              echo "Kafka Brokers: $KAFKA_BROKERS"
              echo "Kafka user: $KAFKA_USER"
              echo "Kafka password: $OBFUSCATED_PASSWORD"
              echo "Kafka Env: $KAFKA_ENV"
              echo "Orders topic name: $ITGTESTS_ORDERS_TOPIC"
              echo "Order Command topic name: $ITGTESTS_ORDER_COMMANDS_TOPIC"
              echo "Containers topic name: $ITGTESTS_CONTAINERS_TOPIC"
              echo "------------------------------------------------------------------"
              echo

              # Check important environments variables are properly set
              if [ -z "$KAFKA_BROKERS" ]; then
                echo "[ERROR] - KAFKA_BROKERS environment variable must be set."
                exit 1
              fi

              if [ "$KAFKA_ENV" != "LOCAL" -a -z "$KAFKA_PASSWORD" ]; then
                echo "[ERROR] - KAFKA_PASSWORD environment variable must be set."
                exit 1
              fi

              # Check that if we are using IBM Event Streams on prem, we are providing the PEM certificate to connect to it.
              if [ "$KAFKA_ENV" == "OCP" ]  && [ ! -f "$PEM_CERT" ]; then
                echo "[ERROR] - The PEM certificate to connect to IBM Event Streams on premise could not be found."
                echo "[ERROR] - Please make sure you have created the kubernetes secret with the PEM certificate and"
                echo "[ERROR] - you have uncommented the mount of such secret in the integration tests yaml file."
                exit 1
              fi

              # Creating the working directory
              mkdir ${WORKING_DIR} && cd ${WORKING_DIR}

              # Clone the repository where the integration tests to be executed are and checkout the specific branch
              git clone ${GITHUB_REPO} && cd ${REPO_NAME} && if [ "master" != "${BRANCH}" ]; then git checkout ${BRANCH}; fi

              # Get into the location for the integration tests
              cd ${ITGTESTS_LOCATION}

              # Execute the integration tests

              # Create the tests reporting file
              touch /tmp/results.txt

              export PYTHONPATH=${PYTHONPATH}:${WORKING_DIR}/${REPO_NAME}/itg-tests

              echo '******************************************'
              echo '******************************************'
              echo '**********   E2E Happy Path   ************'
              echo '******************************************'
              echo '******************************************'

              python -u E2EHappyPath.py && source /tmp/E2EHappyPath.properties

              echo '******************************************'
              echo '******************************************'
              echo '*********   Saga No Container   **********'
              echo '******************************************'
              echo '******************************************'

              python -u Saga_NoContainer.py

              echo '******************************************'
              echo '******************************************'
              echo '**********   Saga No Voyage   ************'
              echo '******************************************'
              echo '******************************************'

              python -u Saga_NoVoyage.py && source /tmp/SagaNoVoyage.properties

              echo '******************************************'
              echo '******************************************'
              echo '**********   Order Cancelled   ***********'
              echo '******************************************'
              echo '******************************************'

              python -u OrderCancellation.py

              echo '******************************************'
              echo '******************************************'
              echo '*********   Container Anomaly   **********'
              echo '******************************************'
              echo '******************************************'

              python -u ContainerAnomaly.py

              echo '****************************************************'
              echo '****************************************************'
              echo '*********   Retry and Dead Letter Queue   **********'
              echo '****************************************************'
              echo '****************************************************'

              python -u ContainerAnomalyDlq.py

              echo
              echo 'END RESULTS:'
              echo
              cat /tmp/results.txt

              echo "---------"
              echo "-- END --"
              echo "---------"
        env:
        # Your working directory within the container
        - name: WORKING_DIR
          value: "/tmp/github"
        # Github repository containing the integration tests to be executed
        - name: GITHUB_REPO
          value: "https://github.com/ibm-cloud-architecture/refarch-kc.git"
        # Specific branch for the integration tests
        - name: BRANCH
          value: "master"
        # Name of the repository
        - name: REPO_NAME
          value: "refarch-kc"
        # Location of the integration tests folder within the repository
        - name: ITGTESTS_LOCATION
          value: "itg-tests/es-it"
        # Event Streams Kafka brokers. You MUST create a configmap in advance with the brokers information:
        # oc create configmap kafka-brokers --from-literal=brokers='<replace with comma-separated list of brokers>' -n <namespace>
        # You can find the list of brokers either in the Event Streams UI or when you login through the CLI: cloudctl es init
        - name: KAFKA_BROKERS
          valueFrom:
            configMapKeyRef:
              name: "kafka-brokers"
              key: brokers
        # Your Event Streams credentials. You can find it in the Event Streams UI on the connect to this cluster link
        # You MUST create this secret in advance with the Event Streams username and password:
        # kubectl create secret generic eventstreams-cred --from-literal=username='<replace with kafka username>' --from-literal=password='<replace with kafka password>'
        - name: KAFKA_USER
          valueFrom:
            secretKeyRef:
              name: "eventstreams-cred"
              key: username
              optional: true
        - name: KAFKA_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "eventstreams-cred"
              key: password
              optional: true
        # Order command microservice's service name
        - name: ORDER_CMD_MS
          value: "ordercommandms-service:9080"
        # Order query microservice's service name
        - name: ORDER_QUERY_MS
          value: "orderqueryms-service:9080"
        # Container microservice's service name
        - name: CONTAINER_SPRING_MS
          value: "springcontainerms-service:8080"
        # Voyage microservice's service name
        - name: VOYAGE_MS
          value: "voyagesms-service:3000"
        # Orders topic name
        - name: ITGTESTS_ORDERS_TOPIC
          #value: "itg-orders"
          valueFrom:
            configMapKeyRef:
              name: kafka-topics
              key: ordersTopic
        # Order Command topic name
        - name: ITGTESTS_ORDER_COMMANDS_TOPIC
          #value: "itg-order-commands"
          valueFrom:
            configMapKeyRef:
              name: kafka-topics
              key: orderCommandsTopic
        # Containers topic name
        - name: ITGTESTS_CONTAINERS_TOPIC
          #value: "itg-containers"
          valueFrom:
            configMapKeyRef:
              name: kafka-topics
              key: containersTopic
        # Container anomaly retry topic name
        - name: ITGTESTS_CONTAINER_ANOMALY_RETRY_TOPIC
          #value: "itg-container-anomaly-retry"
          valueFrom:
            configMapKeyRef:
              name: kafka-topics
              key: containerAnomalyRetryTopic
        # Container anomaly dead topic name
        - name: ITGTESTS_CONTAINER_ANOMALY_DEAD_TOPIC
          #value: "itg-container-anomaly-dead"
          valueFrom:
            configMapKeyRef:
              name: kafka-topics
              key: containerAnomalyDeadTopic
        # Location of your Event Streams pem certificate for ssl connections. You MUST download it in advance.
        # This can be downloaded from the Event Streams UI.
        - name: PEM_CERT
          value: "/tmp/certs/es-cert.pem"
        # Location where the Event Streams pem certificate contained in the eventstreams-pem-file secret will be loaded to.
        volumeMounts:
        - mountPath: "/tmp/certs"
          name: eventstreams-pem-file
      volumes:
         # You MUST create this secret with the Event Streams pem certificate in advance. First, download the Event Streams pem certificate.
         # Then create the secret: oc create secret generic eventstreams-cert-pem --from-file=es-cert.pem=<LOCATION_OF_YOUR_EVENT_STREAMS_PEM_CERTIFICATE> -n <namespace>
         - name: eventstreams-pem-file
           secret:
             secretName: "eventstreams-cert-pem"
             optional: true
      restartPolicy: Never
  backoffLimit: 0
