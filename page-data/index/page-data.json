{"componentChunkName":"component---src-pages-index-mdx","path":"/","result":{"pageContext":{"frontmatter":{"title":"Reefer Container Shipment reference implementation","description":"Reefer Container Shipment solution - IBM Garage Event-Driven Architecture reference implementation"},"relativePagePath":"/index.mdx","titleType":"append","MdxNode":{"id":"94d6fadb-2e95-57b7-b1bd-dadbb731b1fb","children":[],"parent":"22cc9d11-8262-566a-9dc0-1f5a19d36782","internal":{"content":"---\ntitle: Reefer Container Shipment reference implementation\ndescription: Reefer Container Shipment solution - IBM Garage Event-Driven Architecture reference implementation\n---\n\nThe IBM Event-Driven Architecture (EDA) reference implementation illustrates the deployment of real-time analytics on event streams in the context of container shipment in an [event-driven architecture](https://ibm-cloud-architecture.github.io/refarch-eda/) with event backbone, functions as a service, and microservices. It aims to illustrate the different event-driven patterns -- like event sourcing, CQRS and the Saga pattern -- through the use of best practices amd event-driven microservice implementation.\n\n## Target Audiences\n\nYou will be greatly interested by the subjects addressed in this solution if you are:\n\n* **an architect,** as you will get a deeper understanding on how all the components work together, and how to address resiliency & high availability.\n* **a developer,** as you will get a broader view of the solution end-to-end and starter code, as well as insight into practices to reuse during your future implementations.\n* **a project manager,** as you will understand all the artifacts required to develop an EDA-based solution and what is required to perform overall project estimation.\n\n## What you will learn\n\n* How to apply the [event storming methodology](/implementation/event-storming-analysis/) and workshop to analyze the business process for fresh good shipment over sees.\n* How to transform [Domain Driven Design](/implementation/domain-driven-design/) aggregates to microservices.\n* How to implement the different microservices using various event-driven patterns, like CQRS and event sourcing, leveraging Apache Kafka.\n* How to deploy your solution to IBM Cloud Kubernetes service (Public Cloud) or Red Hat OpenShift Container Platform anywhere (Private Cloud).\n* How to use event store (Kafka topics) as source for machine learning data source to build training and test sets.\n* How to implement a Test Driven Development for the Order microservice uisng mockito to avoid Kafka dependency.\n\n## Build and Run\n\nThe end-to-end solution can be demonstrated from a unique user interface and it involves multiple microservices deployed independently. As some of those components are using IBM products or IBM Cloud services by default, you will need to provision these services ahead of time. However, the components of the reference implementation can be deployed into any Kubernetes-based environment and communicate via any Apache Kafka-based event backbone.\n\nMinimal prerequisites for this reference implementation are:\n\n* [IBM Event Streams on Cloud](https://cloud.ibm.com/catalog/services/event-streams) or Event streams within IBM Cloud Pak for integration or a Kafka Strimzi Docker image.\n* Kubernetes Cluster - You can use [Red Hat Openshift](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift) or [Kubernetes](https://cloud.ibm.com/kubernetes/catalog/create) via the IBM Cloud Kubernetes Service.\n* [Databases for PostgreSQL](https://cloud.ibm.com/catalog/services/databases-for-postgresql) - This database is used by the optional [Container Management microservice](microservices/container-management/). We want to illustrate with this implementation a reversibility practice where we start development on the cloud and migrate to private cloud.\n* [Streaming Analytics on IBM Cloud](https://cloud.ibm.com/catalog/services/streaming-analytics) or through the IBM Cloud Pak for Data.\n\nEach project has its own installation explanations and scripts to build, package, test, and deploy to the different deployment environments. These are all detailed in-depth in the respective **Microservices Details** pages, as well as our [DevOps](/infrastructure/devops/) and [GitOps](/infrastructure/gitops/) practices.\n\nTo get started as quickly as possible, follow our **[Quickstart Tutorial](/business-scenario/quickstart-tutorial/)**.\n","type":"Mdx","contentDigest":"168899b2c5adf18064523d9668984582","counter":332,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Reefer Container Shipment reference implementation","description":"Reefer Container Shipment solution - IBM Garage Event-Driven Architecture reference implementation"},"exports":{},"rawBody":"---\ntitle: Reefer Container Shipment reference implementation\ndescription: Reefer Container Shipment solution - IBM Garage Event-Driven Architecture reference implementation\n---\n\nThe IBM Event-Driven Architecture (EDA) reference implementation illustrates the deployment of real-time analytics on event streams in the context of container shipment in an [event-driven architecture](https://ibm-cloud-architecture.github.io/refarch-eda/) with event backbone, functions as a service, and microservices. It aims to illustrate the different event-driven patterns -- like event sourcing, CQRS and the Saga pattern -- through the use of best practices amd event-driven microservice implementation.\n\n## Target Audiences\n\nYou will be greatly interested by the subjects addressed in this solution if you are:\n\n* **an architect,** as you will get a deeper understanding on how all the components work together, and how to address resiliency & high availability.\n* **a developer,** as you will get a broader view of the solution end-to-end and starter code, as well as insight into practices to reuse during your future implementations.\n* **a project manager,** as you will understand all the artifacts required to develop an EDA-based solution and what is required to perform overall project estimation.\n\n## What you will learn\n\n* How to apply the [event storming methodology](/implementation/event-storming-analysis/) and workshop to analyze the business process for fresh good shipment over sees.\n* How to transform [Domain Driven Design](/implementation/domain-driven-design/) aggregates to microservices.\n* How to implement the different microservices using various event-driven patterns, like CQRS and event sourcing, leveraging Apache Kafka.\n* How to deploy your solution to IBM Cloud Kubernetes service (Public Cloud) or Red Hat OpenShift Container Platform anywhere (Private Cloud).\n* How to use event store (Kafka topics) as source for machine learning data source to build training and test sets.\n* How to implement a Test Driven Development for the Order microservice uisng mockito to avoid Kafka dependency.\n\n## Build and Run\n\nThe end-to-end solution can be demonstrated from a unique user interface and it involves multiple microservices deployed independently. As some of those components are using IBM products or IBM Cloud services by default, you will need to provision these services ahead of time. However, the components of the reference implementation can be deployed into any Kubernetes-based environment and communicate via any Apache Kafka-based event backbone.\n\nMinimal prerequisites for this reference implementation are:\n\n* [IBM Event Streams on Cloud](https://cloud.ibm.com/catalog/services/event-streams) or Event streams within IBM Cloud Pak for integration or a Kafka Strimzi Docker image.\n* Kubernetes Cluster - You can use [Red Hat Openshift](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift) or [Kubernetes](https://cloud.ibm.com/kubernetes/catalog/create) via the IBM Cloud Kubernetes Service.\n* [Databases for PostgreSQL](https://cloud.ibm.com/catalog/services/databases-for-postgresql) - This database is used by the optional [Container Management microservice](microservices/container-management/). We want to illustrate with this implementation a reversibility practice where we start development on the cloud and migrate to private cloud.\n* [Streaming Analytics on IBM Cloud](https://cloud.ibm.com/catalog/services/streaming-analytics) or through the IBM Cloud Pak for Data.\n\nEach project has its own installation explanations and scripts to build, package, test, and deploy to the different deployment environments. These are all detailed in-depth in the respective **Microservices Details** pages, as well as our [DevOps](/infrastructure/devops/) and [GitOps](/infrastructure/gitops/) practices.\n\nTo get started as quickly as possible, follow our **[Quickstart Tutorial](/business-scenario/quickstart-tutorial/)**.\n","fileAbsolutePath":"/home/runner/work/refarch-kc/refarch-kc/docs/src/pages/index.mdx"}}}}