{"componentChunkName":"component---src-pages-microservices-application-components-mdx","path":"/microservices/application-components/","result":{"pageContext":{"frontmatter":{"title":"Deployment of application microservices","description":"Deployment of application microservices"},"relativePagePath":"/microservices/application-components.mdx","titleType":"append","MdxNode":{"id":"da042e7d-b7b0-5bae-91da-46129a854f21","children":[],"parent":"4432eafe-061a-5656-a3fb-e7379d5ed738","internal":{"content":"---\ntitle: Deployment of application microservices\ndescription: Deployment of application microservices\n---\n\n\n## Environment prerequisites\n\n### Kafka Topic Creation\n\n\nYou can create the topics using the Event Streams console:\n\n![](images/es-icp-topics.png)\n\nor if you have manually deployed Event Streams or Kafka, you can use commands similar to the snippet below:\n\n```shell\n# get the name of the Kafka pod\n$ export NAMESPACE=<target k8s namespace / ocp project>\n$ export KPOF=$(kubectl get pods  -n ${NAMESPACE} | grep kafka | awk '{print $1;}')\n$ cat ${KPOF}\nrolling-streams-ibm-es-kafka-sts-0\nrolling-streams-ibm-es-kafka-sts-1\nrolling-streams-ibm-es-kafka-sts-2\n# Then get the name of the zookeeper service:\n$ export ZOOKSVC=$(kubectl get svc -n ${NAMESPACE} | grep zoo | awk '{print $1;}' | head -1)\nrolling-streams-ibm-es-zookeeper-fixed-ip-svc-0\n# Then remote exec a shell on one of this broker to configure the topic - for example the \"orders\" topic\n$ kubectl exec -n ${NAMESPACE} -ti ${KPOF} -- bash -c \"/opt/kafka/bin/kafka-topics.sh --create  --zookeeper ${ZOOKSVC}:2181 --replication-factor 1 --partitions 1 --topic orders\"\n```\n\nThe topics that need to be created are:\n\n- `bluewaterContainer`\n- `bluewaterShip`\n- `bluewaterProblem`\n- `orders`\n- `orderCommands`\n- `rejected-orders`\n- `allocated-orders`\n- `errors`\n- `containers`\n- `containerMetrics`\n- `reeferTelemetries`\n\nThe command `scripts/createTopicsOnK8S.sh` creates those topics automatically.\n\n## Docker registries\n\nYou will need a Docker image registry to push and pull your images to and from.  There are multiple options depending on your use cases and we are only documenting a subset of potential solutions, including but not limited to IBM Cloud Container Registry, Docker Hub, Quay, etc.\n\n### IBM Cloud Container Registry\n\nInstall IBM Cloud Container Registry CLI plug-in if needed:\n\n```\nibmcloud plugin install container-registry -r Bluemix\n```\n\n### Define a private image repository\n\nUse the [IBM Cloud Container Registry](https://cloud.ibm.com/containers-kubernetes/catalog/registry) to push your images and then deploy them to any Kubernetes cluster with access to the public internet.  When deploying enterprise applications, it is strongly recommended to use private registry to protect your images from being used and changed by unauthorized users. Private registries must be set up by the cluster administrator to ensure that the credentials to access the private registry are available to the cluster users.\n\nCreate a namespace inside your Container Registry for use here:\n\n```shell\nibmcloud cr namespace-add ibmcaseeda\n```\n\nWe will use this namespace when tagging the docker images for our microservices. Here is an example of tagging:\n\n```shell\ndocker tag ibmcase/kc-ui us.icr.io/ibmcaseeda/kc-ui:latest\n```\n\nTo see the images in your private registry you can use the user interface at [https://cloud.ibm.com/containers-kubernetes/registry/main/private](https://cloud.ibm.com/containers-kubernetes/registry/main/private) or the command:\n\n```shell\nibmcloud cr image-list\n```\n\n#### Private Registry Token\n\nEach Helm Chart specifies the name of the Docker image to load the containers & pods. To enable access from Kubernetes Nodes to your private registry, an image pull secret is required and will be stored in a Kubernetes secret.  If you are using public Docker Hub image repositories, an image pull secret is not required.\n\n*Using secret is also mandatory when registry and clusters are not in the same region.*\n\n* Verify current secrets for a given namespace:\n\n```shell\nkubectl describe secrets -n <target namespace>\n```\n\n* Get a security token: _(these can be `permanent` or `renewable`)_\n\n```shell\nibmcloud cr token-add --description \"private registry secret for <target namespace>\" --non-expiring -q\n```\n\n* To list the available tokens:\n\n```shell\nibmcloud cr tokens\n```\n\nThe result:\n> TOKEN ID     READONLY   EXPIRY   DESCRIPTION\n 2b5ff00e-a..  true       0       token for somebody\n 3dbf72eb-6..  true       0       private registry secret for browncompute\n\n* Get the token for a given token identifier:\n\n```shell\nibmcloud cr token-get cce5a800-...\n```\n\n* Define the secret to store the Event stream API key token information:\n\n```shell\nkubectl --namespace <target namespace> create secret docker-registry\n<target namespace>-registry-secret  --docker-server=<registry_url> --docker-username=token --docker-password=<token_value> --docker-email=<docker_email>\n```\n\n* Verify the secret\n\n```shell\nkubectl get secrets -n <target namespace>\n```\n\nYou will see something like below.\n\n> | NAME  | TYPE  | DATA | AGE |\n| --- | --- | --- | --- |\n| browncompute-registry-secret    |       kubernetes.io/dockerconfigjson     |   1  |       2m |\n| default-token-ggwl2  |  kubernetes.io/service-account-token  | 3  |   41m  |\n| eventstreams-apikey  |  Opaque   |      1   | 24m  |\n\n\n## Basic Kubernetes\n\n### IBM Cloud Kubernetes Service\n\nTo create the cluster follow [this tutorial](https://console.bluemix.net/docs/containers/cs_tutorials.html#cs_cluster_tutorial).\n\n### OpenShift Container Platform 3.11\n\nThis needs to be done once per unique deployment of the entire application.\n\n1. If desired, create a non-default Service Account for usage of deploying and running the K Container reference implementation.  This will become more important in future iterations, so it's best to start small:\n    * Command: `oc create serviceaccount -n <target-namespace> kcontainer-runtime`\n    * Example: `oc create serviceaccount -n eda-refarch kcontainer-runtime`\n1. The target Service Account needs to be allowed to run containers as `anyuid` for the time being:\n    * Command: `oc adm policy add-scc-to-user anyuid -z <service-account-name> -n <target-namespace>`\n    * Example: `oc adm policy add-scc-to-user anyuid -z kcontainer-runtime -n eda-refarch`\n    * NOTE: This requires `cluster-admin` level privileges.\n\n## Deploy application microservices\n\n### Using the master repository\nYou can download the necessary application microservice repsoitories using scripts provided in the master repository:\n\n```shell\ngit clone https://github.com/ibm-cloud-architecture/refarch-kc.git\ncd refarch-kc\n./scripts/clone.sh\n```\n\n### Deploy Order Command microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-order-ms/order-command-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t order-command-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag order-command-ms <private-registry>/<image-namespace>/order-command-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/order-command-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-command-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/ordercommandms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-command-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/ordercommandms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/ordercommandms/templates\n```\n\n* Verify default service is running correctly:\n\nWithout any previously tests done, the call below should return an empty array: `[]`\n\n```shell\ncurl http://<cluster endpoints>:31200/orders\n```\n\n### Deploy Order Query microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-order-ms/order-query-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t order-query-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag order-query-ms <private-registry>/<image-namespace>/order-query-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/order-query-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-query-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/orderqueryms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-query-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/orderqueryms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/orderqueryms/templates\n```\n\n* Verify default service is running correctly:\n\nWithout any previously tests done, the call below should return an empty array: `[]`\n```shell\ncurl http://<cluster endpoints>:31100/orders\n```\n\n### Deploy Container microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-container-ms/SpringContainerMS\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-spring-container-ms:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-spring-container-ms <private-registry>/<image-namespace>/kc-spring-container-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-spring-container-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.caPemFileRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.caPemSecretName=<eventstreams ca pem file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set postgresql.capemRequired=(true/false)` (`true` when connecting to Postgresql Services requiring SSL and CA PEM-secured communication)\n    * `--set postgresql.capemSecret=<postgresql CA pem certificate Secret name>`\n    * `--set postgresql.urlSecret=<postgresql url Secret name>`\n    * `--set postgresql.userSecret=<postgresql user Secret name>`\n    * `--set postgresql.passwordSecret=<postgresql password Secret name>`\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-spring-container-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --set postgresql.capemRequired=true --set postgresql.capemSecret=postgresql-ca-pem --set postgresql.urlSecret=postgresql-url --set postgresql.userSecret=postgresql-user --set postgresql.passwordSecret=postgresql-pwd --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/springcontainerms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n  ```shell\n  helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-spring-container-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set postgresql.capemRequired=true --set postgresql.capemSecret=postgresql-ca-pem --set postgresql.urlSecret=postgresql-url --set postgresql.userSecret=postgresql-user --set postgresql.passwordSecret=postgresql-pwd --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/springcontainerms\n  ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/springcontainerms/templates\n```\n\n* Verify default service is running correctly:\n\n```shell\ncurl http://cluster-endpoints:31900/containers\n```\n\n### Deploy Voyages microservice\n\nThe *Voyage microservice* is a simple nodejs app to mockup schedule of vessels between two harbors. It is here to illustrate Kafka integration with nodejs app.\n\n* Go to the repo\n\n```shell\ncd refarch-kc-ms/voyages-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-voyages-ms:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-voyages-ms <private-registry>/<image-namespace>/kc-voyages-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-voyages-ms:latest\n```\n\n* Generate application YAMLs via `helm template`:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.caPemFileRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.caPemSecretName=<eventstreams ca pem file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-voyages-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.caPemFileRequired=true --set eventstreams.caPemSecretName=es-ca-pemfile --output-dir templates --namespace eda-refarch chart/voyagesms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-voyages-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/voyagesms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/voyagesms/templates\n```\n\n* Verify default service is running correctly:\n```shell\ncurl http://cluster-endpoint:31000/voyage\n```\n\n### Deploy the Fleet Simulator microservice\n\nThe *Fleet simulator* is to move vessels from one harbors to another, and send container metrics while the containers are on a vessel. It has some predefined simulation to trigger some events.\n\n* Go to the repo\n\n```shell\ncd cd refarch-kc-ms/fleet-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-fleet-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-fleet-ms <private-registry>/<image-namespace>/kc-fleet-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-fleet-ms:latest\n```\n\n* Generate application YAMLs via `helm template`:\n    - `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    - `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    - `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    - `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    - `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    - `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    - `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    - `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    - `--set serviceAccountName=<service-account-name>`\n    - `--namespace <target-namespace>`\n    - `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-fleet-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/fleetms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-fleet-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/fleetms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/fleetms/templates\n```\n\n* Verify default service is running correctly:\n\n  At the beginning the call below should return an empty array: `[]`\n```shell\ncurl http://cluster-endpoint:31300/fleetms/fleets\n```\n\n### Deploy User Interface microservice\n\n* Go to the repo\n\n```\ncd refarch-kc-ui/\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-ui:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-ui <private-registry>/<image-namespace>/kc-ui:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-ui:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n  - `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n  - `--set image.tag=latest`\n  - `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n  - `--set image.pullPolicy=Always`\n  - `--set eventstreams.env=ICP`\n  - `--set eventstreams.brokersConfigMap=<kafka brokers ConfigMap name>`\n  - `--set serviceAccountName=<service-account-name>`\n  - `--namespace <target-namespace>`\n  - `--output-dir <local-template-directory>`\n\n```shell\n# Example parameters\nhelm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-ui --set image.tag=latest --set image.pullPolicy=Always --set eventstreams.env=ICP --set eventstreams.brokersConfigMap=kafka-brokers --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/kc-ui\n```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/kc-ui/templates\n```\n\n* Verify the installed app\n\nPoint your web browser to [http://cluster-endpoints:31010](#) and login with username: eddie@email.com and password Eddie.\n\n## Integration Tests\n\nIntegration tests are provided in the [itg-tests](itg-tests/) directory and are designed to be run in cluster with the rest of the application components.  However, they are regular Python scripts that can be adapted to be runnable anywhere, given the correct Kafka endpoints and configuration information.  For simplicity, this quick walkthrough will document how you can build and deploy Docker images that will run the integration tests inside the cluster, with the results visible via `kubectl logs` and the rest of the application's APIs.\n\n* Build the base Docker image\n```shell\n# From the root of the 'refarch-kc' repository\ndocker build -f docker/docker-python-tools -t osowski/python-tools .\ndocker push osowski/python-tools\n```\n\nThe above image is a base Python image with our integration tests, defined in the `itg-tests` directory.  It is a long-running Flask process that provides a simple web server, so once deployed, it will remain available to \"exec\" into for additional in-cluster CLI interaction.  However, for simplicity, we have defined a few integration scenarios, using a Kubernetes Deployment and multiple Kubernetes Jobs, that will automate some of the integration test scenarios.\n\n* Update the `itg-tests/kustomization.yaml` file with the specifics for your `python-tools` Docker image, changing the `newName` and `newTag` fields, as appropriate, along with the `namespace` field.\n\n* Then run the following the command to apply the customization and deploy to the platform:\n```shell\n# From the root of the 'refarch-kc' repository\nkubectl apply -k itg-tests/\n```\n**NOTE:** `kubectl` must be at level `1.14` or higher for the `-k` flag to be available.\n\nThis Kubernetes YAML will create one Deployment and one Job.  The long-running Deployment will run the [OrdersPython/OrderConsumer.py](#) script to watch for order events in the Kafka backend, while the short-lived Job create all the necessary order events via the [es-it/ProducerOrderEvents.py](#) script and publish them to Kafka.\n\n* View the output of the `es-it/ProducerOrderEvents.py` Job:\n```shell\n(kubectl/oc) get jobs | grep kcontainer\n(kubectl/oc) logs -f <pod_name>\n```\n\n* View the output of the `OrdersPython/OrderConsumer.py` Deployment:\n```shell\n(kubectl/oc) get pods | grep consumer\n(kubectl/oc) logs -f <pod_name>\n```\n\nYou should see the same Order ID created by the Job in the output of the Deployment's container.\n\n## Universal deployment considerations\n\nWhen deploying kafka consumer it is important to assess the horizontal pod autoscaler settings and needs, as adding consumers will not address scalability if the number of partitions in the topic(s) to consume does not match the increase of consumers. So disable HPA by default. If you want to use HPA you also need to ensure that a metrics-server is running, then set the number of partition, and the `hpa.maxReplicas` to the number of partitions.\n","type":"Mdx","contentDigest":"80568a715c529f16bd9244d0723f2f54","counter":345,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Deployment of application microservices","description":"Deployment of application microservices"},"exports":{},"rawBody":"---\ntitle: Deployment of application microservices\ndescription: Deployment of application microservices\n---\n\n\n## Environment prerequisites\n\n### Kafka Topic Creation\n\n\nYou can create the topics using the Event Streams console:\n\n![](images/es-icp-topics.png)\n\nor if you have manually deployed Event Streams or Kafka, you can use commands similar to the snippet below:\n\n```shell\n# get the name of the Kafka pod\n$ export NAMESPACE=<target k8s namespace / ocp project>\n$ export KPOF=$(kubectl get pods  -n ${NAMESPACE} | grep kafka | awk '{print $1;}')\n$ cat ${KPOF}\nrolling-streams-ibm-es-kafka-sts-0\nrolling-streams-ibm-es-kafka-sts-1\nrolling-streams-ibm-es-kafka-sts-2\n# Then get the name of the zookeeper service:\n$ export ZOOKSVC=$(kubectl get svc -n ${NAMESPACE} | grep zoo | awk '{print $1;}' | head -1)\nrolling-streams-ibm-es-zookeeper-fixed-ip-svc-0\n# Then remote exec a shell on one of this broker to configure the topic - for example the \"orders\" topic\n$ kubectl exec -n ${NAMESPACE} -ti ${KPOF} -- bash -c \"/opt/kafka/bin/kafka-topics.sh --create  --zookeeper ${ZOOKSVC}:2181 --replication-factor 1 --partitions 1 --topic orders\"\n```\n\nThe topics that need to be created are:\n\n- `bluewaterContainer`\n- `bluewaterShip`\n- `bluewaterProblem`\n- `orders`\n- `orderCommands`\n- `rejected-orders`\n- `allocated-orders`\n- `errors`\n- `containers`\n- `containerMetrics`\n- `reeferTelemetries`\n\nThe command `scripts/createTopicsOnK8S.sh` creates those topics automatically.\n\n## Docker registries\n\nYou will need a Docker image registry to push and pull your images to and from.  There are multiple options depending on your use cases and we are only documenting a subset of potential solutions, including but not limited to IBM Cloud Container Registry, Docker Hub, Quay, etc.\n\n### IBM Cloud Container Registry\n\nInstall IBM Cloud Container Registry CLI plug-in if needed:\n\n```\nibmcloud plugin install container-registry -r Bluemix\n```\n\n### Define a private image repository\n\nUse the [IBM Cloud Container Registry](https://cloud.ibm.com/containers-kubernetes/catalog/registry) to push your images and then deploy them to any Kubernetes cluster with access to the public internet.  When deploying enterprise applications, it is strongly recommended to use private registry to protect your images from being used and changed by unauthorized users. Private registries must be set up by the cluster administrator to ensure that the credentials to access the private registry are available to the cluster users.\n\nCreate a namespace inside your Container Registry for use here:\n\n```shell\nibmcloud cr namespace-add ibmcaseeda\n```\n\nWe will use this namespace when tagging the docker images for our microservices. Here is an example of tagging:\n\n```shell\ndocker tag ibmcase/kc-ui us.icr.io/ibmcaseeda/kc-ui:latest\n```\n\nTo see the images in your private registry you can use the user interface at [https://cloud.ibm.com/containers-kubernetes/registry/main/private](https://cloud.ibm.com/containers-kubernetes/registry/main/private) or the command:\n\n```shell\nibmcloud cr image-list\n```\n\n#### Private Registry Token\n\nEach Helm Chart specifies the name of the Docker image to load the containers & pods. To enable access from Kubernetes Nodes to your private registry, an image pull secret is required and will be stored in a Kubernetes secret.  If you are using public Docker Hub image repositories, an image pull secret is not required.\n\n*Using secret is also mandatory when registry and clusters are not in the same region.*\n\n* Verify current secrets for a given namespace:\n\n```shell\nkubectl describe secrets -n <target namespace>\n```\n\n* Get a security token: _(these can be `permanent` or `renewable`)_\n\n```shell\nibmcloud cr token-add --description \"private registry secret for <target namespace>\" --non-expiring -q\n```\n\n* To list the available tokens:\n\n```shell\nibmcloud cr tokens\n```\n\nThe result:\n> TOKEN ID     READONLY   EXPIRY   DESCRIPTION\n 2b5ff00e-a..  true       0       token for somebody\n 3dbf72eb-6..  true       0       private registry secret for browncompute\n\n* Get the token for a given token identifier:\n\n```shell\nibmcloud cr token-get cce5a800-...\n```\n\n* Define the secret to store the Event stream API key token information:\n\n```shell\nkubectl --namespace <target namespace> create secret docker-registry\n<target namespace>-registry-secret  --docker-server=<registry_url> --docker-username=token --docker-password=<token_value> --docker-email=<docker_email>\n```\n\n* Verify the secret\n\n```shell\nkubectl get secrets -n <target namespace>\n```\n\nYou will see something like below.\n\n> | NAME  | TYPE  | DATA | AGE |\n| --- | --- | --- | --- |\n| browncompute-registry-secret    |       kubernetes.io/dockerconfigjson     |   1  |       2m |\n| default-token-ggwl2  |  kubernetes.io/service-account-token  | 3  |   41m  |\n| eventstreams-apikey  |  Opaque   |      1   | 24m  |\n\n\n## Basic Kubernetes\n\n### IBM Cloud Kubernetes Service\n\nTo create the cluster follow [this tutorial](https://console.bluemix.net/docs/containers/cs_tutorials.html#cs_cluster_tutorial).\n\n### OpenShift Container Platform 3.11\n\nThis needs to be done once per unique deployment of the entire application.\n\n1. If desired, create a non-default Service Account for usage of deploying and running the K Container reference implementation.  This will become more important in future iterations, so it's best to start small:\n    * Command: `oc create serviceaccount -n <target-namespace> kcontainer-runtime`\n    * Example: `oc create serviceaccount -n eda-refarch kcontainer-runtime`\n1. The target Service Account needs to be allowed to run containers as `anyuid` for the time being:\n    * Command: `oc adm policy add-scc-to-user anyuid -z <service-account-name> -n <target-namespace>`\n    * Example: `oc adm policy add-scc-to-user anyuid -z kcontainer-runtime -n eda-refarch`\n    * NOTE: This requires `cluster-admin` level privileges.\n\n## Deploy application microservices\n\n### Using the master repository\nYou can download the necessary application microservice repsoitories using scripts provided in the master repository:\n\n```shell\ngit clone https://github.com/ibm-cloud-architecture/refarch-kc.git\ncd refarch-kc\n./scripts/clone.sh\n```\n\n### Deploy Order Command microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-order-ms/order-command-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t order-command-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag order-command-ms <private-registry>/<image-namespace>/order-command-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/order-command-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-command-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/ordercommandms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-command-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/ordercommandms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/ordercommandms/templates\n```\n\n* Verify default service is running correctly:\n\nWithout any previously tests done, the call below should return an empty array: `[]`\n\n```shell\ncurl http://<cluster endpoints>:31200/orders\n```\n\n### Deploy Order Query microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-order-ms/order-query-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t order-query-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag order-query-ms <private-registry>/<image-namespace>/order-query-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/order-query-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-query-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/orderqueryms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/order-query-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/orderqueryms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/orderqueryms/templates\n```\n\n* Verify default service is running correctly:\n\nWithout any previously tests done, the call below should return an empty array: `[]`\n```shell\ncurl http://<cluster endpoints>:31100/orders\n```\n\n### Deploy Container microservice\n\n* Go to the repo\n\n```shell\ncd refarch-kc-container-ms/SpringContainerMS\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-spring-container-ms:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-spring-container-ms <private-registry>/<image-namespace>/kc-spring-container-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-spring-container-ms:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.caPemFileRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.caPemSecretName=<eventstreams ca pem file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set postgresql.capemRequired=(true/false)` (`true` when connecting to Postgresql Services requiring SSL and CA PEM-secured communication)\n    * `--set postgresql.capemSecret=<postgresql CA pem certificate Secret name>`\n    * `--set postgresql.urlSecret=<postgresql url Secret name>`\n    * `--set postgresql.userSecret=<postgresql user Secret name>`\n    * `--set postgresql.passwordSecret=<postgresql password Secret name>`\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-spring-container-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --set postgresql.capemRequired=true --set postgresql.capemSecret=postgresql-ca-pem --set postgresql.urlSecret=postgresql-url --set postgresql.userSecret=postgresql-user --set postgresql.passwordSecret=postgresql-pwd --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/springcontainerms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n  ```shell\n  helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-spring-container-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set postgresql.capemRequired=true --set postgresql.capemSecret=postgresql-ca-pem --set postgresql.urlSecret=postgresql-url --set postgresql.userSecret=postgresql-user --set postgresql.passwordSecret=postgresql-pwd --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/springcontainerms\n  ```\n\n* Deploy application using `kubectl/oc apply`:\n\n```shell\n(kubectl/oc) apply -f templates/springcontainerms/templates\n```\n\n* Verify default service is running correctly:\n\n```shell\ncurl http://cluster-endpoints:31900/containers\n```\n\n### Deploy Voyages microservice\n\nThe *Voyage microservice* is a simple nodejs app to mockup schedule of vessels between two harbors. It is here to illustrate Kafka integration with nodejs app.\n\n* Go to the repo\n\n```shell\ncd refarch-kc-ms/voyages-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-voyages-ms:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-voyages-ms <private-registry>/<image-namespace>/kc-voyages-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-voyages-ms:latest\n```\n\n* Generate application YAMLs via `helm template`:\n    * `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    * `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    * `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    * `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    * `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    * `--set eventstreams.caPemFileRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    * `--set eventstreams.caPemSecretName=<eventstreams ca pem file secret name>` (only used when connecting to Event Streams via ICP4I)\n    * `--set serviceAccountName=<service-account-name>`\n    * `--namespace <target-namespace>`\n    * `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-voyages-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.caPemFileRequired=true --set eventstreams.caPemSecretName=es-ca-pemfile --output-dir templates --namespace eda-refarch chart/voyagesms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-voyages-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/voyagesms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/voyagesms/templates\n```\n\n* Verify default service is running correctly:\n```shell\ncurl http://cluster-endpoint:31000/voyage\n```\n\n### Deploy the Fleet Simulator microservice\n\nThe *Fleet simulator* is to move vessels from one harbors to another, and send container metrics while the containers are on a vessel. It has some predefined simulation to trigger some events.\n\n* Go to the repo\n\n```shell\ncd cd refarch-kc-ms/fleet-ms\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-fleet-ms:latest -f Dockerfile.multistage .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-fleet-ms <private-registry>/<image-namespace>/kc-fleet-ms:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-fleet-ms:latest\n```\n\n* Generate application YAMLs via `helm template`:\n    - `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n    - `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n    - `--set kafka.brokersConfigMap=<kafka brokers ConfigMap name>`\n    - `--set eventstreams.enabled=(true/false)` (`true` when connecting to Event Streams of any kind, `false` when connecting to Kafka directly)\n    - `--set eventstreams.apikeyConfigMap=<kafka api key Secret name>`\n    - `--set eventstreams.truststoreRequired=(true/false)` (`true` when connecting to Event Streams via ICP4I)\n    - `--set eventstreams.truststoreSecret=<eventstreams jks file secret name>` (only used when connecting to Event Streams via ICP4I)\n    - `--set eventstreams.truststorePassword=<eventstreams jks password>` (only used when connecting to Event Streams via ICP4I)\n    - `--set serviceAccountName=<service-account-name>`\n    - `--namespace <target-namespace>`\n    - `--output-dir <local-template-directory>`\n  Example using Event Streams via ICP4I:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-fleet-ms --set kafka.brokersConfigMap=es-kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=es-eventstreams-apikey --set serviceAccountName=kcontainer-runtime --set eventstreams.truststoreRequired=true --set eventstreams.truststoreSecret=es-truststore-jks --set eventstreams.truststorePassword=password --output-dir templates --namespace eda-refarch chart/fleetms\n   ```\n  Example using Event Streams hosted on IBM Cloud:\n   ```shell\n   helm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-fleet-ms --set kafka.brokersConfigMap=kafka-brokers --set eventstreams.enabled=true --set eventstreams.apikeyConfigMap=eventstreams-apikey --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/fleetms\n   ```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/fleetms/templates\n```\n\n* Verify default service is running correctly:\n\n  At the beginning the call below should return an empty array: `[]`\n```shell\ncurl http://cluster-endpoint:31300/fleetms/fleets\n```\n\n### Deploy User Interface microservice\n\n* Go to the repo\n\n```\ncd refarch-kc-ui/\n```\n\n* Build the image\n\n```shell\ndocker build -t kc-ui:latest -f Dockerfile .\n```\n\n* Tag the image\n\n```shell\ndocker tag kc-ui <private-registry>/<image-namespace>/kc-ui:latest\n```\n\n* Push the image\n\n```shell\ndocker login <private-registry>\ndocker push <private-registry>/<image-namespace>/kc-ui:latest\n```\n\n* Generate application YAMLs via `helm template` with the following parameters:\n  - `--set image.repository=<private-registry>/<image-namespace>/<image-repository>`\n  - `--set image.tag=latest`\n  - `--set image.pullSecret=<private-registry-pullsecret>` (only required if pulling from an external private registry)\n  - `--set image.pullPolicy=Always`\n  - `--set eventstreams.env=ICP`\n  - `--set eventstreams.brokersConfigMap=<kafka brokers ConfigMap name>`\n  - `--set serviceAccountName=<service-account-name>`\n  - `--namespace <target-namespace>`\n  - `--output-dir <local-template-directory>`\n\n```shell\n# Example parameters\nhelm template --set image.repository=rhos-quay.internal-network.local/browncompute/kc-ui --set image.tag=latest --set image.pullPolicy=Always --set eventstreams.env=ICP --set eventstreams.brokersConfigMap=kafka-brokers --set serviceAccountName=kcontainer-runtime --output-dir templates --namespace eda-refarch chart/kc-ui\n```\n\n* Deploy application using `kubectl/oc apply`:\n```shell\n(kubectl/oc) apply -f templates/kc-ui/templates\n```\n\n* Verify the installed app\n\nPoint your web browser to [http://cluster-endpoints:31010](#) and login with username: eddie@email.com and password Eddie.\n\n## Integration Tests\n\nIntegration tests are provided in the [itg-tests](itg-tests/) directory and are designed to be run in cluster with the rest of the application components.  However, they are regular Python scripts that can be adapted to be runnable anywhere, given the correct Kafka endpoints and configuration information.  For simplicity, this quick walkthrough will document how you can build and deploy Docker images that will run the integration tests inside the cluster, with the results visible via `kubectl logs` and the rest of the application's APIs.\n\n* Build the base Docker image\n```shell\n# From the root of the 'refarch-kc' repository\ndocker build -f docker/docker-python-tools -t osowski/python-tools .\ndocker push osowski/python-tools\n```\n\nThe above image is a base Python image with our integration tests, defined in the `itg-tests` directory.  It is a long-running Flask process that provides a simple web server, so once deployed, it will remain available to \"exec\" into for additional in-cluster CLI interaction.  However, for simplicity, we have defined a few integration scenarios, using a Kubernetes Deployment and multiple Kubernetes Jobs, that will automate some of the integration test scenarios.\n\n* Update the `itg-tests/kustomization.yaml` file with the specifics for your `python-tools` Docker image, changing the `newName` and `newTag` fields, as appropriate, along with the `namespace` field.\n\n* Then run the following the command to apply the customization and deploy to the platform:\n```shell\n# From the root of the 'refarch-kc' repository\nkubectl apply -k itg-tests/\n```\n**NOTE:** `kubectl` must be at level `1.14` or higher for the `-k` flag to be available.\n\nThis Kubernetes YAML will create one Deployment and one Job.  The long-running Deployment will run the [OrdersPython/OrderConsumer.py](#) script to watch for order events in the Kafka backend, while the short-lived Job create all the necessary order events via the [es-it/ProducerOrderEvents.py](#) script and publish them to Kafka.\n\n* View the output of the `es-it/ProducerOrderEvents.py` Job:\n```shell\n(kubectl/oc) get jobs | grep kcontainer\n(kubectl/oc) logs -f <pod_name>\n```\n\n* View the output of the `OrdersPython/OrderConsumer.py` Deployment:\n```shell\n(kubectl/oc) get pods | grep consumer\n(kubectl/oc) logs -f <pod_name>\n```\n\nYou should see the same Order ID created by the Job in the output of the Deployment's container.\n\n## Universal deployment considerations\n\nWhen deploying kafka consumer it is important to assess the horizontal pod autoscaler settings and needs, as adding consumers will not address scalability if the number of partitions in the topic(s) to consume does not match the increase of consumers. So disable HPA by default. If you want to use HPA you also need to ensure that a metrics-server is running, then set the number of partition, and the `hpa.maxReplicas` to the number of partitions.\n","fileAbsolutePath":"/home/runner/work/refarch-kc/refarch-kc/docs/src/pages/microservices/application-components.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}