{"componentChunkName":"component---src-pages-quickstart-tutorial-deploy-on-ibm-openlabs-mdx","path":"/quickstart-tutorial/deploy-on-ibm-openlabs/","result":{"pageContext":{"frontmatter":{"title":"Quickstart Tutorial","description":"Simple end-to-end deployment scenario for the KContainer Shipping Container Reference Implementation.","tabs":["Deploy on IBM OpenLabs","Deploy on OpenShift Playgrounds"]},"relativePagePath":"/quickstart-tutorial/deploy-on-ibm-openlabs.mdx","titleType":"append","MdxNode":{"id":"89ed20b8-6d8c-5a35-b17c-a778a21f467e","children":[],"parent":"25e2161c-deba-5759-a3e2-5e40f6e31376","internal":{"content":"---\ntitle: Quickstart Tutorial\ndescription: Simple end-to-end deployment scenario for the KContainer Shipping Container Reference Implementation.\ntabs: ['Deploy on IBM OpenLabs', 'Deploy on OpenShift Playgrounds']\n---\n\n## Introduction\n\nIn this tutorial, you will:\n\n- Deploy the reference implementation to a standalone OpenShift cluster.\n- Create an order via the UI.\n- Check on existing orders.\n- View information about the Fleet.\n\nEach of these business processes will be executed step-by-step using the demonstration APIs and some scripts.\n\n### Pre-requisites\n\n- **Red Hat OpenShift Container Platform** - this quickstart utilizes either the [OpenShift Playgrounds](https://learn.openshift.com/playgrounds/openshift45/) or the [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift).\n- ... and that's it!!! Everything else is provided for you via OpenShift Operators or through existing GitHub repositories.\n- Additional self-paced learning can be done to integrate the deployed reference implementation with additional Kafka offerings, such as _IBM Event Streams_, _Red Hat AMQ Streams_, or _Confluent Platform_.\n\n## Deploy the reference implementation\n\n### IBM OpenLabs\n\nIn this section, we are going to see how to deploy the KContainer Shipping Container Reference Implementation on the [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift) hosted environment.\n\n1. Go to [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift) in a browser and click on `Launch Lab` button for **Lab 6**.\n\n  ![OpenLabs1](images/openLabs1.png)\n\n1. Sign in with your IBM Cloud account or register for an IBM Cloud account.\n\n  ![OpenLabs2](images/openLabs2.png)\n\n1. You will be presented with a dialog asking you whether you have an **Opportunity Id** or not. If you don't have it or don't no, just select **No** and click on **Launch Lab**.\n\n1. You should now see your IBM OpenLabs environment.\n\n  ![OpenLabs4](images/openLabs4.png)\n\n1. On the left hand side navigation menu, click on the **Quick Links and Common Commnads** section. Now, if you scroll down on the instructions shown on your screen, you should reach the **Commonly Used Command** section of these and in there you should see an `oc login ...` command to get your terminal associated to this IBM OpenLabs Lab 6 logged into the OpenShift cluster that you will be working with for this quickstart tutorial. Click on the `oc login...` command and you should see a `Login successful` message on the terminal.\n\n  ![OpenLabs8](images/openLabs8.png)\n\n1. In the terminal associated to your lab, download the [kcontainer-quickstart-ocp.sh](https://github.com/ibm-cloud-architecture/refarch-kc/tree/master/scripts/quickstart/kcontainer-quickstart-ocp.sh) file:\n\n  ```\n  curl -o kcontainer-quickstart-ocp.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/kcontainer-quickstart-ocp.sh\n  chmod +x kcontainer-quickstart-ocp.sh\n  ```\n\n  <br/>\n\n  ![OpenLabs9](images/openLabs9.png)\n\n1. Execute the quickstart deployment script with the following command:\n\n  ```\n  ./kcontainer-quickstart-ocp.sh --skip-login\n  ```\n  **IMPORTANT:** do not forget the **- -skip-login** flag since we have already logged into the RedHat OpenShift cluster above.\n\n1. Wait for the deployment to be active and ready when you are prompted with `Press any key to continue once an order has been submitted...`.\n\n  ![OpenLabs10](images/openLabs10.png)\n\n1. Grab the User Interface Microservice url and credentials and open it up in your web browser.\n\n  ![OpenLabs11](images/openLabs11.png)\n\n1. You can also check all the resources created by the `kcontainer-quickstart-ocp.sh` script in the RedHat OpenShift console by clicking on the OpenShift web console quick link presented at the top of the instructions section of the OpenLabs Lab6 website.\n\n  ![OpenLabs5](images/openLabs5.png)\n\n1. You should now see your OpenShift web console.\n\n  ![OpenLabs7](images/openLabs7.png)\n\n## Run the Demo\n\nIn this section, we are going to guide you through different scenarios to not only demonstrate the end goal of the KContainer application of creating an order to ship goods from a source port to a destination port but some of the EDA patterns that it implements as well.\n\n### Setup\n\nFirst thing we want to do is to be able to inspect the state of each of the components involved in the creation of an oder. These are:\n\n- [User Interface](/microservices/user-interface/) - Will provide us with a user interface.\n- [Order Command](/microservices/order-command/) - Will take care of the write responibilities in the CQRS pattern.\n- [Order Query](/microservices/order-query/) - Will take care of the read responsibilities in the CQRS pattern.\n- [Container Management](/microservices/container-management/) - Will take care of the management of the containers.\n- [Voyage Management](/microservices/voyage-management/) - Will take care of the management of the voyages for the different ships in our fleet.\n\nIn order to check the state of each of these components and see how these evolve and react to the events happening within our application, we need to expose them individually through OpenShift routes. Of course, this is not a best practice for production-ready applications but a tool for us to be able to understand what is going on behind the scenes in our Event Driven Architecure KContainer reference implementation.\n\nWe have created the following `get_state.sh` script that will grab the route for each of the KContainer components involved in the creation of an order listed above, set these up with the appropriate context path and poke them to retrieve their state so that you don't have to do so manually in the terminal and web browser (which you may want for a client demo so that it may be a bit more visual...).\n\nTo grab the script and make it executable, run the following in your terminal:\n\n```shell\ncurl -o get_state.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/get_state.sh\nchmod +x get_state.sh\n```\n\nThese script runs and infinite while loop to get the state of each of the KContainer components involved in the creation of an order every time to press any key. Execute the script by running `./get_state.sh`:\n\n```shell\nThese are the endpoints for each of the KContainer components\n-------------------------------------------------------------\n* User Interface --> kc-ui-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/api/orders/GoodManuf\n* Order Command  --> order-command-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/orders\n* Order Query    --> order-query-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/orders\n* Containers     --> spring-container-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/containers\n* Voyages        --> voyages-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/voyage\n\nPress any key to get the state for each of the KContainer components\n\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:28:08 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[]\n\nOrder Command:\n\nOrder Query:\n[]\n\nContainers:\n[]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nWe can see that the initial state of our KContainer application does not count with any order already in the system which is what we should expect after a new clean deployment of the solution. However, it does have 4 voyages already in the system (disregard the `plannedDeparture` and `plannedArrival` attributes. We are **only** interested in the `srcPort`, `dstPort` and `freeCapacity` attributes). Also, there is no container at all in the system which we need if we want to carry goods from a source port to a destination port.\n\nAs a result, the first thing we need to do before creating an order is to add a new container at the source port into our system. For that, the Container Management component exposes and API which the following `create_container.sh` script will make use of. On a new terminal tab, download the script and make it executable:\n\n```shell\ncurl -o create_container.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/create_container.sh\nchmod +x create_container.sh\n```\n\nCreate a container of size 10 executing `./create_container.sh 10`\n\n```shell\nCreating a new container with ID = 8090 and size = 10\n\n{\n  \"id\": \"8090\",\n  \"latitude\": 31.4,\n  \"longitude\": 121.5,\n  \"type\": \"Reefer\",\n  \"status\": \"Empty\",\n  \"brand\": \"itgtests-brand\",\n  \"currentCity\": \"Shanghai\",\n  \"capacity\": 10,\n  \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n  \"updatedAt\": \"2021-03-08T12:28:56.851+0000\"\n}\n```\n\nAs you can see, we have created an `Empty` container whose `currentCity` is `Shanghai`, where there is also a voyage to carry goods from to `Oakland`, and `capacity` of `10`.\n\nYou can go back to the terminal tab where you executed the `get_state.sh` script and hit any key again to see what the state of the system is now:\n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:29:27 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[]\n\nOrder Command:\n\nOrder Query:\n[]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Empty\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 10,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:28:56.851+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nthat shows, again, the container we have just created is reflected in the system as you would expect.\n\nWe are now ready to create a new order in our KContainer application to carry some goods up to `10` from `Shanghai`, where we created the new container, to `Oakland` which is one of the existing voayages in the system.\n\n### KContainer Manufacturer creating an order\n\nIn this section, we are going to create a new order to ship goods of 10 items overseas from `Shanghai` to `Oakland` as the `GoodManuf` manufacturer. By creating this order, we are going to observe how our Event Driven Architecture KContainer reference implementation works both from the outside (the order gets `assigned` which means it has a container assigned to carry the goods and a voyage allocated to ship the container overseas) and from the inside looking at the CQRS, SAGA, Event Sourcing, etc patterns as well as the different events in Kafka, our event backbone.\n\nOpen up the KContainer application user interface on your web browser by pointing it to the route you got presented with at the end of the previous [Deploy the reference implementation](#deploy-the-reference-implementation) section. You can also find the route executing:\n\n  ```shell\n  oc get route kc-ui -o jsonpath=\"{.spec.host}\"\n  ```\n\n![kc-login](images/kc-login.png)\n\nTo log in to the home page, you will need the following user email and password:\n\n- Email: `eddie@email.com`\n- Password: `Eddie`\n\nThe initial UI homepage shows an illustrated version of the business process. There are four tiles that can be used to simulate different parts of the outlined business process.\n\n![kc-home](images/kc-home2.png)\n\nClick on the `Initiate Orders - Manufacturer` tile to create a new _'fresh product'_ order to ship overseas. This simulates the activity that would usually be carried out by the manufacturer in our scenario.\n\nTo represent different manufacturers, the first select box has been designed to support multiple scenarios in the future. For the purposes of this quickstart tutorial, select `GoodManuf`.\n\n![](images/kc-manuf-select.png)\n\nOnce the manufacturer is selected, a list of existing orders will be displayed. As expected, there is no orders in the system yet for the `GoodManuf` manufacturer.\n\n![](images/kc-orders2.png)\n\nClick on `New Order` and a form to create a new order will be displayed on the right hand side of your screen:\n\n![](images/kc-new-order.png)\n\nNow, in order for the demo to work, we **must** make sure that the new order we submit has\n\n- `10` or less `Quantity`\n- `Shanghai` as the `Pickup Address City`\n- `Oakland` as the `Destination Address City`\n\nthe reason for this is that we created in the [Setup](#setup) section a container in `Shanghai` with a capacity of `10` and we know there is only one voyage whose source port is Shanghai and that voyage ships containers to `Oakland`. The rest of the attributes, will not have effect on the order management. **DO NOT** click `Submit` yet.\n\n![](images/kc-order-form.png)\n\nWe are ready to submit our new order for the KContainer application to process it. But first, let's go over what is meant to happen behind the scenes as a result:\n\n![](images/flow.png)\n\n1. Clicking the Submit button on the user interface will call the API to create a new order in the `Order Command` component. As explained in the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), any request from the users of the application or any third party will become a command event (specific type of event) that will get registered in our event backbone and that our application will need to act upon. That is, the system will obey to a command. As a result, we should see a `CreateOrderCommand` event in the `orderCommands` topic. The idea behind Event Sourcing and logging the actions we want our system to take into our event backbone as commands is to make sure these actions are taken no matter what. Commands will not get \"marked\" as \"accomplished/executed\" until we are 100% sure the needed actions have been taken as a result. To make sure of this, we are making use of the technology and capabilities that Kafka provides (such us transactionality and idempontence) along with the [Consume-transform-produce loop pattern](/implementation/consume-transform-produce/). \n\n1. The Order Command component is listening to the `orderCommands` topic for those `CreateOrderCommand` command events to go off and create those new orders. As a result, it will pick up our `CreateOrderCommand` event and will create the corresponding new order. In this case, it will be as \"simple\" as creating a new record into an in-memory database and then, once again, to comply with the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), logging an event into the event backbone as the fact that has happened. As a result, we should see an `OrderCreated` event being dropped in the `orders` topic. Only then, the initial `CreateOrderCommand` command event will get marked as \"accomplished/executed\" (which translates in the Kafka terminology as get its offset committed). The actions of creating a new object into the `Order Commands` in-memory's database and sending out the `OrderCreated` event into the event backbone are the two actions (could be more if we needed) that must happen as a result and the [Consume-transform-produce loop pattern](/implementation/consume-transform-produce/) is what makes sure of it.\n\n1. Now, we have created a new order in the `Order Command` component and dropped an `OrderCreated` event into the event backbone following the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/) as something that has happened. This allows any other component in our system to be aware of this change (and any other that happens) and be able to appropriately react to these if needed as a result. This makes our components completely decoupled through asynchronous communication, which makes our application reactive, resilient and scalable (see [The Reactive Manifesto](https://www.reactivemanifesto.org/)). \n\n1. However, the creation of a new order \"object\" in the `Order Command` component is useless for us from the business point of view because our end goal is to get those orders shipped overseas and, in order to do that, we need to allocate a container and assign a voyage to the order or reject the order. To allocate a container and assign a voyage to an order another two components of our distributed solution need to step in. The need of taking several actions on distributed components for an end goal is what is known as a long running transaction. To address this long running transaction, we implemented the choreography variant of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) where the `OrderCreated` event will trigger a sequence of actions to happen in a distributed manner before \"marking\" the new order object created previously as `Assigned` (which means accepted and ready for delivery) or `Rejected` (in the case that there wasn't a suitable container or voyage available). Until then, the order will remain as `Pending`.\n\n1. As said above, the `OrderCreated` event will trigger a long running transaction in our distributed system on a choreography manner. That is, the next actor in such long running transaction, the `Container Manager` component is listening to the `orders` topic for `OrderCreated` events. Once it sees one of those events, it will try to allocate a container for that order. If it finds one it will allocate the container to the order and will, following the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/) again, log that fact in the form of a `ContainerAllocated` event into `orders` topic of the event backbone. If a suitable container could not be found, then it will drop a `ContainerNotFound` event into the `orders` topic of the event backbone so the rest of the components involved in this long running transaction can carry out a compensation process accordingly (we will cover this later on).\n\n1. We hope to have a `ContainerAllocated` event into the `orders` topic by now which will then trigger the next action on this long running transaction part of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) that involves the `Voyages Manager`. The `Voyages Manager` is listening for `ContainerAllocated` events in the `orders` topic in our event backbone in order to assign a voyage to these. As a result, it will then log a `VoyageAssigned` event if a suitable voyage for the order (source port and destination port) and for its allocated container (capacity) has been found. If a suitable voyage could not be found, a `VoyageNotFound` event will get logged into the `orders` topic in our event backbone instead so that a compensation process is carried out (more on this later).\n\n1. Finally, the `Order Command` component, which initiated the long running transaction as a result of having created a new order, listens for `VoyageAssigned` events in the `orders` topic in our event backbone. Once the `VoyageAssigned` event is received, the order is marked as `Assigned` and the long running transaction is considered successfully completed.\n\nOk, this time we really are ready for creating a new order. Make sure you have the `get_state.sh` script running on a terminal so that you execute it **right after** hitting the submit button for the new order in the user interface. This way, we would see the intermediate `Pending` state of the order:\n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:40:43 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"pending\"\n  }\n]\n\nOrder Command:\n[\n  {\n    \"customerID\": \"GoodManuf\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"productID\": \"Fresh product 1\",\n    \"status\": \"pending\"\n  }\n]\n\nOrder Query:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"pending\"\n  }\n]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Loaded\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 0,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:40:39.882+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nwhere we can already see the following interesting facts:\n\n  1. As per the `Order Command` component, a new order with ID `0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc` has been created and it is still in `Pending` state since the long running transaction implemented using the SAGA pattern has not yet finalised (since a voyage has not yet been assigned. See the `Voyage Manager` state where no voyage has yet decreased their `freeCapacity`).\n  1. As per the `Container Manager` component, the container with ID `8090` we previously created on purpose is now loaded (`capacity` is `0`).\n  1. In the `User Interface` and `Command Query` components, we can not only see see the full information of the order compared to what the `Order Command` component shows but also that the container with ID `8090` has been allocated to it. The reason for this is that the `Order Command` component implements the write portion of the [**Command Query Responsibility Segregation pattern**](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/) whereas the `Order Query` component implements the read portion of it. As a result, the `Order Command` component only cares about managing the state of the order whereas the `Order Query` component implements the complex queries our application needs to address by building the projections on the appropriate data that is gathered from the different distributed components by processing the events flowing through the event backbone it is interested in.\n\nIf we had the ability to refresh the user interface and select the `GoodManuf` manufacturer once again to get its orders listed, we should see the order is also in `pending` state.\n\n![](images/kc-order-pending.png)\n\nIf we now, after 10 secs aprox, hit again any key in the terminal where we have running the `get_state.sh` script: \n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:43:03 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"assigned\",\n    \"voyageID\": \"101\"\n  }\n]\n\nOrder Command:\n[\n  {\n    \"customerID\": \"GoodManuf\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"productID\": \"Fresh product 1\",\n    \"status\": \"assigned\"\n  }\n]\n\nOrder Query:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"assigned\",\n    \"voyageID\": \"101\"\n  }\n]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Loaded\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 0,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:40:39.882+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 990\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nwe should see that:\n\n  1. As per the `Order Command` component, the order is now `Assigned` as a result of having a voyage assigned to it.\n  1. As per the `User Interface` and `Order Query` commands, we should see the voyage that has been assigned to the order (ID `101`). Again, we see how the `Order Query` component is building up those projections with the data it is interested in from the different distributed components through the events being published in the event backbone ([Command Query Responsibility Segregation pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/))\n  1. As per the `Voyages Management` component, we can see that voyage with ID `101` has now `freeCapacity` of `990` as opposed to the `freeCapacity` of `1000` at the beginning as a result of having allocated our container with ID `8090` and capacity of `10` on it.\n\nAgain, if we refresh the user interface and select the `GoodManuf` manufacturer, we should now see the order in `assigned` state.\n\n![](images/kc-order-assigned.png)\n\nFinally, we want to inspect the events in both the `orderCommands` and `orders` topics of our event backbone.\n\n1. Check out the events in the `orderCommands` topic by executing in a terminal:\n\n  ```shell\n  oc rsh my-cluster-kafka-0 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --timeout-ms 10000 --topic order-commands\n  ```\n  \n  ```json\n  {\n      \"payload\":{\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n          \"productID\":\"Fresh product 1\",\n          \"customerID\":\"GoodManuf\",\n          \"quantity\":10,\n          \"pickupAddress\":{\n              \"street\":\"Some street\",\"\n              city\":\"Shanghai\",\n              \"country\":\"China\",\n              \"state\":\"XX\",\n              \"zipcode\":\"12345\"\n          },\n          \"pickupDate\":\"2021-03-09T23:00:00.000Z\",\n          \"destinationAddress\":{\n              \"street\":\"Other Street\",\n              \"city\":\"Oakland\",\n              \"country\":\"USA\",\n              \"state\":\"CA\",\n              \"zipcode\":\"12345\"\n          },\n          \"expectedDeliveryDate\":\"2021-03-16T23:00:00.000Z\",\n          \"status\":\"toBeCreated\"\n      },\n      \"timestampMillis\":1615207239077,\n      \"type\":\"CreateOrderCommand\",\n      \"version\":\"1\"\n  }\n  ```\n\n  where we can see the `CreateOrderCommand` command event as a result of calling the create new order API of the `Order Command` component and applying the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/).\n\n1. Check out the events in the `orders` topic as a result of the new order command event above by executing in a terminal:\n\n  ```shell\n  oc rsh my-cluster-kafka-0 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --timeout-ms 10000 --topic orders\n  ```\n\n  ```json\n  {\n      \"payload\":{\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n          \"productID\":\"Fresh product 1\",\n          \"customerID\":\"GoodManuf\",\n          \"quantity\":10,\n          \"pickupAddress\":{\n              \"street\":\"Some street\",\n              \"city\":\"Shanghai\",\n              \"country\":\"China\",\n              \"state\":\"XX\",\n              \"zipcode\":\"12345\"\n          },\n          \"pickupDate\":\"2021-03-09T23:00:00.000Z\",\n          \"destinationAddress\":{\n              \"street\":\"Other Street\",\n              \"city\":\"Oakland\",\n              \"country\":\"USA\",\n              \"state\":\"CA\",\n              \"zipcode\":\"12345\"\n          },\n          \"expectedDeliveryDate\":\"2021-03-16T23:00:00.000Z\",\n          \"status\":\"pending\"\n      },\n      \"timestampMillis\":1615207239330,\n      \"type\":\"OrderCreated\",\n      \"version\":\"1\"\n  }\n\n  {\n      \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n      \"payload\":{\n          \"containerID\":\"8090\",\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\"\n      },\n      \"timestamp\":1615207239909,\n      \"type\":\"ContainerAllocated\"\n  }\n\n  {\n      \"timestamp\":1615207250000,\n      \"type\":\"VoyageAssigned\",\n      \"version\":\"1\",\n      \"payload\":{\n          \"voyageID\":\"101\",\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\"\n      }\n  }\n  ```\n\n  where we can see the `OrderCreated` event as a result of having processed the initial `CreateOrderCommand` command event from the `orderCommands` topic followed by the `ContainerAllocated` and `VoyageAssigned` events that are part of the long running transaction of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) the `OrderCreated` events triggers.\n\n## Clean up\n\nIf you wish to cleanup your environment to the initial state where no order or container was created and your kafka topics where empty, execute the following steps from the terminal:\n\n1. Scale all the Appsody/OpenLiberty apps to 0 replicas so that there is no consumer or consumer group hooked up to any kafka topic\n\n  ```\n  for APP in $(oc get AppsodyApplication,OpenLibertyApplication | grep \"-\" | awk '{print $1}'); do oc patch $APP --type 'json' -p '[{\"op\":\"add\", \"path\":\"/spec/replicas\", \"value\":0}]'; done\n  ```\n\n1. Delete the postgresql database that stores the state of the existing containers so all those existing containers are removed\n\n  ```\n  oc delete pod/postgres-db-postgresql-0\n  ```\n\n1. Delete all kafka topics so that we get rid of all existing events in them\n\n  ```\n  for i in `oc get kafkatopics | grep '-' | awk '{print $1}'`; do oc delete kafkatopic $i; done\n  ```\n\n1. Wait until the below command returns 1. This is to ensure that all the topics have been removed (it may take a couple of minutes to the Strimzi operator to accomplish the task)\n\n  ```\n  oc exec -it my-cluster-kafka-0 -- ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092 | wc -l\n  ```\n\n1. Download the definition of the kafka topics in order to recreate these\n\n  ```\n  curl -o kafka-topics.yaml https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc-gitops/master/environments/dev/apps/refarch-kc/base/kafka/kafka-topics.yaml\n  ```\n\n1. Recreate the kafka topics\n\n  ```\n  oc apply -f kafka-topics.yaml\n  ```\n\n1. Wait until the below command returns 10 or greater. This is to ensure that all the topics have been created (it may take a couple of minutes to the Strimzi operator to accomplish the task)\n\n  ```\n  oc exec -it my-cluster-kafka-0 -- ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092 | wc -l\n  ```\n\n1. Scale all the Appsody/OpenLiberty apps back to 1 replica\n\n  ```\n  for APP in $(oc get AppsodyApplication,OpenLibertyApplication | grep \"-\" | awk '{print $1}'); do oc patch $APP --type 'json' -p '[{\"op\":\"add\", \"path\":\"/spec/replicas\", \"value\":1}]'; done\n  ```\n\n1. You may need to wait a couple of minutes for these Appsody and OpenLiberty applications to get started. You can check the status of these running\n\n  ```\n  oc get pods -l app.kubernetes.io/part-of=refarch-kc\n  ```\n\n_This quickstart guide will be updated as the project evolves and new capability is added. If you have any issues or queries with this quickstart guide, please [raise an issue](https://github.com/ibm-cloud-architecture/refarch-kc/issues) in the github repo._\n","type":"Mdx","contentDigest":"c68656c5f1b4f9c6f232e121f30af18f","counter":370,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Quickstart Tutorial","description":"Simple end-to-end deployment scenario for the KContainer Shipping Container Reference Implementation.","tabs":["Deploy on IBM OpenLabs","Deploy on OpenShift Playgrounds"]},"exports":{},"rawBody":"---\ntitle: Quickstart Tutorial\ndescription: Simple end-to-end deployment scenario for the KContainer Shipping Container Reference Implementation.\ntabs: ['Deploy on IBM OpenLabs', 'Deploy on OpenShift Playgrounds']\n---\n\n## Introduction\n\nIn this tutorial, you will:\n\n- Deploy the reference implementation to a standalone OpenShift cluster.\n- Create an order via the UI.\n- Check on existing orders.\n- View information about the Fleet.\n\nEach of these business processes will be executed step-by-step using the demonstration APIs and some scripts.\n\n### Pre-requisites\n\n- **Red Hat OpenShift Container Platform** - this quickstart utilizes either the [OpenShift Playgrounds](https://learn.openshift.com/playgrounds/openshift45/) or the [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift).\n- ... and that's it!!! Everything else is provided for you via OpenShift Operators or through existing GitHub repositories.\n- Additional self-paced learning can be done to integrate the deployed reference implementation with additional Kafka offerings, such as _IBM Event Streams_, _Red Hat AMQ Streams_, or _Confluent Platform_.\n\n## Deploy the reference implementation\n\n### IBM OpenLabs\n\nIn this section, we are going to see how to deploy the KContainer Shipping Container Reference Implementation on the [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift) hosted environment.\n\n1. Go to [IBM OpenLabs](https://developer.ibm.com/openlabs/openshift) in a browser and click on `Launch Lab` button for **Lab 6**.\n\n  ![OpenLabs1](images/openLabs1.png)\n\n1. Sign in with your IBM Cloud account or register for an IBM Cloud account.\n\n  ![OpenLabs2](images/openLabs2.png)\n\n1. You will be presented with a dialog asking you whether you have an **Opportunity Id** or not. If you don't have it or don't no, just select **No** and click on **Launch Lab**.\n\n1. You should now see your IBM OpenLabs environment.\n\n  ![OpenLabs4](images/openLabs4.png)\n\n1. On the left hand side navigation menu, click on the **Quick Links and Common Commnads** section. Now, if you scroll down on the instructions shown on your screen, you should reach the **Commonly Used Command** section of these and in there you should see an `oc login ...` command to get your terminal associated to this IBM OpenLabs Lab 6 logged into the OpenShift cluster that you will be working with for this quickstart tutorial. Click on the `oc login...` command and you should see a `Login successful` message on the terminal.\n\n  ![OpenLabs8](images/openLabs8.png)\n\n1. In the terminal associated to your lab, download the [kcontainer-quickstart-ocp.sh](https://github.com/ibm-cloud-architecture/refarch-kc/tree/master/scripts/quickstart/kcontainer-quickstart-ocp.sh) file:\n\n  ```\n  curl -o kcontainer-quickstart-ocp.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/kcontainer-quickstart-ocp.sh\n  chmod +x kcontainer-quickstart-ocp.sh\n  ```\n\n  <br/>\n\n  ![OpenLabs9](images/openLabs9.png)\n\n1. Execute the quickstart deployment script with the following command:\n\n  ```\n  ./kcontainer-quickstart-ocp.sh --skip-login\n  ```\n  **IMPORTANT:** do not forget the **- -skip-login** flag since we have already logged into the RedHat OpenShift cluster above.\n\n1. Wait for the deployment to be active and ready when you are prompted with `Press any key to continue once an order has been submitted...`.\n\n  ![OpenLabs10](images/openLabs10.png)\n\n1. Grab the User Interface Microservice url and credentials and open it up in your web browser.\n\n  ![OpenLabs11](images/openLabs11.png)\n\n1. You can also check all the resources created by the `kcontainer-quickstart-ocp.sh` script in the RedHat OpenShift console by clicking on the OpenShift web console quick link presented at the top of the instructions section of the OpenLabs Lab6 website.\n\n  ![OpenLabs5](images/openLabs5.png)\n\n1. You should now see your OpenShift web console.\n\n  ![OpenLabs7](images/openLabs7.png)\n\n## Run the Demo\n\nIn this section, we are going to guide you through different scenarios to not only demonstrate the end goal of the KContainer application of creating an order to ship goods from a source port to a destination port but some of the EDA patterns that it implements as well.\n\n### Setup\n\nFirst thing we want to do is to be able to inspect the state of each of the components involved in the creation of an oder. These are:\n\n- [User Interface](/microservices/user-interface/) - Will provide us with a user interface.\n- [Order Command](/microservices/order-command/) - Will take care of the write responibilities in the CQRS pattern.\n- [Order Query](/microservices/order-query/) - Will take care of the read responsibilities in the CQRS pattern.\n- [Container Management](/microservices/container-management/) - Will take care of the management of the containers.\n- [Voyage Management](/microservices/voyage-management/) - Will take care of the management of the voyages for the different ships in our fleet.\n\nIn order to check the state of each of these components and see how these evolve and react to the events happening within our application, we need to expose them individually through OpenShift routes. Of course, this is not a best practice for production-ready applications but a tool for us to be able to understand what is going on behind the scenes in our Event Driven Architecure KContainer reference implementation.\n\nWe have created the following `get_state.sh` script that will grab the route for each of the KContainer components involved in the creation of an order listed above, set these up with the appropriate context path and poke them to retrieve their state so that you don't have to do so manually in the terminal and web browser (which you may want for a client demo so that it may be a bit more visual...).\n\nTo grab the script and make it executable, run the following in your terminal:\n\n```shell\ncurl -o get_state.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/get_state.sh\nchmod +x get_state.sh\n```\n\nThese script runs and infinite while loop to get the state of each of the KContainer components involved in the creation of an order every time to press any key. Execute the script by running `./get_state.sh`:\n\n```shell\nThese are the endpoints for each of the KContainer components\n-------------------------------------------------------------\n* User Interface --> kc-ui-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/api/orders/GoodManuf\n* Order Command  --> order-command-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/orders\n* Order Query    --> order-query-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/orders\n* Containers     --> spring-container-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/containers\n* Voyages        --> voyages-ms-shipping.dte-ocp44-new-aghbjd-915b3b336cabec458a7c7ec2aa7c625f-0000.us-east.containers.appdomain.cloud/voyage\n\nPress any key to get the state for each of the KContainer components\n\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:28:08 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[]\n\nOrder Command:\n\nOrder Query:\n[]\n\nContainers:\n[]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nWe can see that the initial state of our KContainer application does not count with any order already in the system which is what we should expect after a new clean deployment of the solution. However, it does have 4 voyages already in the system (disregard the `plannedDeparture` and `plannedArrival` attributes. We are **only** interested in the `srcPort`, `dstPort` and `freeCapacity` attributes). Also, there is no container at all in the system which we need if we want to carry goods from a source port to a destination port.\n\nAs a result, the first thing we need to do before creating an order is to add a new container at the source port into our system. For that, the Container Management component exposes and API which the following `create_container.sh` script will make use of. On a new terminal tab, download the script and make it executable:\n\n```shell\ncurl -o create_container.sh https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc/master/scripts/quickstart/create_container.sh\nchmod +x create_container.sh\n```\n\nCreate a container of size 10 executing `./create_container.sh 10`\n\n```shell\nCreating a new container with ID = 8090 and size = 10\n\n{\n  \"id\": \"8090\",\n  \"latitude\": 31.4,\n  \"longitude\": 121.5,\n  \"type\": \"Reefer\",\n  \"status\": \"Empty\",\n  \"brand\": \"itgtests-brand\",\n  \"currentCity\": \"Shanghai\",\n  \"capacity\": 10,\n  \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n  \"updatedAt\": \"2021-03-08T12:28:56.851+0000\"\n}\n```\n\nAs you can see, we have created an `Empty` container whose `currentCity` is `Shanghai`, where there is also a voyage to carry goods from to `Oakland`, and `capacity` of `10`.\n\nYou can go back to the terminal tab where you executed the `get_state.sh` script and hit any key again to see what the state of the system is now:\n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:29:27 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[]\n\nOrder Command:\n\nOrder Query:\n[]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Empty\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 10,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:28:56.851+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nthat shows, again, the container we have just created is reflected in the system as you would expect.\n\nWe are now ready to create a new order in our KContainer application to carry some goods up to `10` from `Shanghai`, where we created the new container, to `Oakland` which is one of the existing voayages in the system.\n\n### KContainer Manufacturer creating an order\n\nIn this section, we are going to create a new order to ship goods of 10 items overseas from `Shanghai` to `Oakland` as the `GoodManuf` manufacturer. By creating this order, we are going to observe how our Event Driven Architecture KContainer reference implementation works both from the outside (the order gets `assigned` which means it has a container assigned to carry the goods and a voyage allocated to ship the container overseas) and from the inside looking at the CQRS, SAGA, Event Sourcing, etc patterns as well as the different events in Kafka, our event backbone.\n\nOpen up the KContainer application user interface on your web browser by pointing it to the route you got presented with at the end of the previous [Deploy the reference implementation](#deploy-the-reference-implementation) section. You can also find the route executing:\n\n  ```shell\n  oc get route kc-ui -o jsonpath=\"{.spec.host}\"\n  ```\n\n![kc-login](images/kc-login.png)\n\nTo log in to the home page, you will need the following user email and password:\n\n- Email: `eddie@email.com`\n- Password: `Eddie`\n\nThe initial UI homepage shows an illustrated version of the business process. There are four tiles that can be used to simulate different parts of the outlined business process.\n\n![kc-home](images/kc-home2.png)\n\nClick on the `Initiate Orders - Manufacturer` tile to create a new _'fresh product'_ order to ship overseas. This simulates the activity that would usually be carried out by the manufacturer in our scenario.\n\nTo represent different manufacturers, the first select box has been designed to support multiple scenarios in the future. For the purposes of this quickstart tutorial, select `GoodManuf`.\n\n![](images/kc-manuf-select.png)\n\nOnce the manufacturer is selected, a list of existing orders will be displayed. As expected, there is no orders in the system yet for the `GoodManuf` manufacturer.\n\n![](images/kc-orders2.png)\n\nClick on `New Order` and a form to create a new order will be displayed on the right hand side of your screen:\n\n![](images/kc-new-order.png)\n\nNow, in order for the demo to work, we **must** make sure that the new order we submit has\n\n- `10` or less `Quantity`\n- `Shanghai` as the `Pickup Address City`\n- `Oakland` as the `Destination Address City`\n\nthe reason for this is that we created in the [Setup](#setup) section a container in `Shanghai` with a capacity of `10` and we know there is only one voyage whose source port is Shanghai and that voyage ships containers to `Oakland`. The rest of the attributes, will not have effect on the order management. **DO NOT** click `Submit` yet.\n\n![](images/kc-order-form.png)\n\nWe are ready to submit our new order for the KContainer application to process it. But first, let's go over what is meant to happen behind the scenes as a result:\n\n![](images/flow.png)\n\n1. Clicking the Submit button on the user interface will call the API to create a new order in the `Order Command` component. As explained in the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), any request from the users of the application or any third party will become a command event (specific type of event) that will get registered in our event backbone and that our application will need to act upon. That is, the system will obey to a command. As a result, we should see a `CreateOrderCommand` event in the `orderCommands` topic. The idea behind Event Sourcing and logging the actions we want our system to take into our event backbone as commands is to make sure these actions are taken no matter what. Commands will not get \"marked\" as \"accomplished/executed\" until we are 100% sure the needed actions have been taken as a result. To make sure of this, we are making use of the technology and capabilities that Kafka provides (such us transactionality and idempontence) along with the [Consume-transform-produce loop pattern](/implementation/consume-transform-produce/). \n\n1. The Order Command component is listening to the `orderCommands` topic for those `CreateOrderCommand` command events to go off and create those new orders. As a result, it will pick up our `CreateOrderCommand` event and will create the corresponding new order. In this case, it will be as \"simple\" as creating a new record into an in-memory database and then, once again, to comply with the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), logging an event into the event backbone as the fact that has happened. As a result, we should see an `OrderCreated` event being dropped in the `orders` topic. Only then, the initial `CreateOrderCommand` command event will get marked as \"accomplished/executed\" (which translates in the Kafka terminology as get its offset committed). The actions of creating a new object into the `Order Commands` in-memory's database and sending out the `OrderCreated` event into the event backbone are the two actions (could be more if we needed) that must happen as a result and the [Consume-transform-produce loop pattern](/implementation/consume-transform-produce/) is what makes sure of it.\n\n1. Now, we have created a new order in the `Order Command` component and dropped an `OrderCreated` event into the event backbone following the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/) as something that has happened. This allows any other component in our system to be aware of this change (and any other that happens) and be able to appropriately react to these if needed as a result. This makes our components completely decoupled through asynchronous communication, which makes our application reactive, resilient and scalable (see [The Reactive Manifesto](https://www.reactivemanifesto.org/)). \n\n1. However, the creation of a new order \"object\" in the `Order Command` component is useless for us from the business point of view because our end goal is to get those orders shipped overseas and, in order to do that, we need to allocate a container and assign a voyage to the order or reject the order. To allocate a container and assign a voyage to an order another two components of our distributed solution need to step in. The need of taking several actions on distributed components for an end goal is what is known as a long running transaction. To address this long running transaction, we implemented the choreography variant of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) where the `OrderCreated` event will trigger a sequence of actions to happen in a distributed manner before \"marking\" the new order object created previously as `Assigned` (which means accepted and ready for delivery) or `Rejected` (in the case that there wasn't a suitable container or voyage available). Until then, the order will remain as `Pending`.\n\n1. As said above, the `OrderCreated` event will trigger a long running transaction in our distributed system on a choreography manner. That is, the next actor in such long running transaction, the `Container Manager` component is listening to the `orders` topic for `OrderCreated` events. Once it sees one of those events, it will try to allocate a container for that order. If it finds one it will allocate the container to the order and will, following the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/) again, log that fact in the form of a `ContainerAllocated` event into `orders` topic of the event backbone. If a suitable container could not be found, then it will drop a `ContainerNotFound` event into the `orders` topic of the event backbone so the rest of the components involved in this long running transaction can carry out a compensation process accordingly (we will cover this later on).\n\n1. We hope to have a `ContainerAllocated` event into the `orders` topic by now which will then trigger the next action on this long running transaction part of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) that involves the `Voyages Manager`. The `Voyages Manager` is listening for `ContainerAllocated` events in the `orders` topic in our event backbone in order to assign a voyage to these. As a result, it will then log a `VoyageAssigned` event if a suitable voyage for the order (source port and destination port) and for its allocated container (capacity) has been found. If a suitable voyage could not be found, a `VoyageNotFound` event will get logged into the `orders` topic in our event backbone instead so that a compensation process is carried out (more on this later).\n\n1. Finally, the `Order Command` component, which initiated the long running transaction as a result of having created a new order, listens for `VoyageAssigned` events in the `orders` topic in our event backbone. Once the `VoyageAssigned` event is received, the order is marked as `Assigned` and the long running transaction is considered successfully completed.\n\nOk, this time we really are ready for creating a new order. Make sure you have the `get_state.sh` script running on a terminal so that you execute it **right after** hitting the submit button for the new order in the user interface. This way, we would see the intermediate `Pending` state of the order:\n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:40:43 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"pending\"\n  }\n]\n\nOrder Command:\n[\n  {\n    \"customerID\": \"GoodManuf\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"productID\": \"Fresh product 1\",\n    \"status\": \"pending\"\n  }\n]\n\nOrder Query:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"pending\"\n  }\n]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Loaded\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 0,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:40:39.882+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 1000\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nwhere we can already see the following interesting facts:\n\n  1. As per the `Order Command` component, a new order with ID `0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc` has been created and it is still in `Pending` state since the long running transaction implemented using the SAGA pattern has not yet finalised (since a voyage has not yet been assigned. See the `Voyage Manager` state where no voyage has yet decreased their `freeCapacity`).\n  1. As per the `Container Manager` component, the container with ID `8090` we previously created on purpose is now loaded (`capacity` is `0`).\n  1. In the `User Interface` and `Command Query` components, we can not only see see the full information of the order compared to what the `Order Command` component shows but also that the container with ID `8090` has been allocated to it. The reason for this is that the `Order Command` component implements the write portion of the [**Command Query Responsibility Segregation pattern**](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/) whereas the `Order Query` component implements the read portion of it. As a result, the `Order Command` component only cares about managing the state of the order whereas the `Order Query` component implements the complex queries our application needs to address by building the projections on the appropriate data that is gathered from the different distributed components by processing the events flowing through the event backbone it is interested in.\n\nIf we had the ability to refresh the user interface and select the `GoodManuf` manufacturer once again to get its orders listed, we should see the order is also in `pending` state.\n\n![](images/kc-order-pending.png)\n\nIf we now, after 10 secs aprox, hit again any key in the terminal where we have running the `get_state.sh` script: \n\n```shell\nThese are the states for each of the KContainer components at Mon  8 Mar 2021 13:43:03 CET\n---------------------------------------------------------------------------------------\nUser Interface:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"assigned\",\n    \"voyageID\": \"101\"\n  }\n]\n\nOrder Command:\n[\n  {\n    \"customerID\": \"GoodManuf\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"productID\": \"Fresh product 1\",\n    \"status\": \"assigned\"\n  }\n]\n\nOrder Query:\n[\n  {\n    \"containerID\": \"8090\",\n    \"customerID\": \"GoodManuf\",\n    \"destinationAddress\": {\n      \"city\": \"Oakland\",\n      \"country\": \"USA\",\n      \"state\": \"CA\",\n      \"street\": \"Other Street\",\n      \"zipcode\": \"12345\"\n    },\n    \"expectedDeliveryDate\": \"2021-03-16T23:00:00.000Z\",\n    \"orderID\": \"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n    \"pickupAddress\": {\n      \"city\": \"Shanghai\",\n      \"country\": \"China\",\n      \"state\": \"XX\",\n      \"street\": \"Some street\",\n      \"zipcode\": \"12345\"\n    },\n    \"pickupDate\": \"2021-03-09T23:00:00.000Z\",\n    \"productID\": \"Fresh product 1\",\n    \"quantity\": 10,\n    \"status\": \"assigned\",\n    \"voyageID\": \"101\"\n  }\n]\n\nContainers:\n[\n  {\n    \"id\": \"8090\",\n    \"latitude\": 31.4,\n    \"longitude\": 121.5,\n    \"type\": \"Reefer\",\n    \"status\": \"Loaded\",\n    \"brand\": \"itgtests-brand\",\n    \"currentCity\": \"Shanghai\",\n    \"capacity\": 0,\n    \"createdAt\": \"2021-03-08T12:28:56.851+0000\",\n    \"updatedAt\": \"2021-03-08T12:40:39.882+0000\"\n  }\n]\n\nVoyages:\n[\n  {\n    \"voyageID\": \"100\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Oakland\",\n    \"plannedDeparture\": \"2019-02-15T20:20Z\",\n    \"destPort\": \"Shanghai\",\n    \"plannedArrival\": \"2019-02-30T20:20Z\",\n    \"freeCapacity\": 400\n  },\n  {\n    \"voyageID\": \"101\",\n    \"shipID\": \"JimminyCricket\",\n    \"srcPort\": \"Shanghai\",\n    \"plannedDeparture\": \"2019-03-05T20:20Z\",\n    \"destPort\": \"Oakland\",\n    \"plannedArrival\": \"2019-03-30T20:20Z\",\n    \"freeCapacity\": 990\n  },\n  {\n    \"voyageID\": \"200\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"NYC\",\n    \"plannedDeparture\": \"2019-02-20T20:20Z\",\n    \"destPort\": \"London\",\n    \"plannedArrival\": \"2019-02-300T20:20Z\",\n    \"freeCapacity\": 200\n  },\n  {\n    \"voyageID\": \"201\",\n    \"shipID\": \"BlackBear\",\n    \"srcPort\": \"London\",\n    \"plannedDeparture\": \"2019-03-02T20:20Z\",\n    \"destPort\": \"NYC\",\n    \"plannedArrival\": \"2019-03-10T20:20Z\",\n    \"freeCapacity\": 300\n  }\n]\n\n\nPress any key to get the state for each of the KContainer components\n```\n\nwe should see that:\n\n  1. As per the `Order Command` component, the order is now `Assigned` as a result of having a voyage assigned to it.\n  1. As per the `User Interface` and `Order Query` commands, we should see the voyage that has been assigned to the order (ID `101`). Again, we see how the `Order Query` component is building up those projections with the data it is interested in from the different distributed components through the events being published in the event backbone ([Command Query Responsibility Segregation pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/))\n  1. As per the `Voyages Management` component, we can see that voyage with ID `101` has now `freeCapacity` of `990` as opposed to the `freeCapacity` of `1000` at the beginning as a result of having allocated our container with ID `8090` and capacity of `10` on it.\n\nAgain, if we refresh the user interface and select the `GoodManuf` manufacturer, we should now see the order in `assigned` state.\n\n![](images/kc-order-assigned.png)\n\nFinally, we want to inspect the events in both the `orderCommands` and `orders` topics of our event backbone.\n\n1. Check out the events in the `orderCommands` topic by executing in a terminal:\n\n  ```shell\n  oc rsh my-cluster-kafka-0 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --timeout-ms 10000 --topic order-commands\n  ```\n  \n  ```json\n  {\n      \"payload\":{\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n          \"productID\":\"Fresh product 1\",\n          \"customerID\":\"GoodManuf\",\n          \"quantity\":10,\n          \"pickupAddress\":{\n              \"street\":\"Some street\",\"\n              city\":\"Shanghai\",\n              \"country\":\"China\",\n              \"state\":\"XX\",\n              \"zipcode\":\"12345\"\n          },\n          \"pickupDate\":\"2021-03-09T23:00:00.000Z\",\n          \"destinationAddress\":{\n              \"street\":\"Other Street\",\n              \"city\":\"Oakland\",\n              \"country\":\"USA\",\n              \"state\":\"CA\",\n              \"zipcode\":\"12345\"\n          },\n          \"expectedDeliveryDate\":\"2021-03-16T23:00:00.000Z\",\n          \"status\":\"toBeCreated\"\n      },\n      \"timestampMillis\":1615207239077,\n      \"type\":\"CreateOrderCommand\",\n      \"version\":\"1\"\n  }\n  ```\n\n  where we can see the `CreateOrderCommand` command event as a result of calling the create new order API of the `Order Command` component and applying the [Event Sourcing pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/).\n\n1. Check out the events in the `orders` topic as a result of the new order command event above by executing in a terminal:\n\n  ```shell\n  oc rsh my-cluster-kafka-0 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --timeout-ms 10000 --topic orders\n  ```\n\n  ```json\n  {\n      \"payload\":{\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n          \"productID\":\"Fresh product 1\",\n          \"customerID\":\"GoodManuf\",\n          \"quantity\":10,\n          \"pickupAddress\":{\n              \"street\":\"Some street\",\n              \"city\":\"Shanghai\",\n              \"country\":\"China\",\n              \"state\":\"XX\",\n              \"zipcode\":\"12345\"\n          },\n          \"pickupDate\":\"2021-03-09T23:00:00.000Z\",\n          \"destinationAddress\":{\n              \"street\":\"Other Street\",\n              \"city\":\"Oakland\",\n              \"country\":\"USA\",\n              \"state\":\"CA\",\n              \"zipcode\":\"12345\"\n          },\n          \"expectedDeliveryDate\":\"2021-03-16T23:00:00.000Z\",\n          \"status\":\"pending\"\n      },\n      \"timestampMillis\":1615207239330,\n      \"type\":\"OrderCreated\",\n      \"version\":\"1\"\n  }\n\n  {\n      \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\",\n      \"payload\":{\n          \"containerID\":\"8090\",\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\"\n      },\n      \"timestamp\":1615207239909,\n      \"type\":\"ContainerAllocated\"\n  }\n\n  {\n      \"timestamp\":1615207250000,\n      \"type\":\"VoyageAssigned\",\n      \"version\":\"1\",\n      \"payload\":{\n          \"voyageID\":\"101\",\n          \"orderID\":\"0e75b3f5-a15e-42c9-a05b-9c8c55a4e0dc\"\n      }\n  }\n  ```\n\n  where we can see the `OrderCreated` event as a result of having processed the initial `CreateOrderCommand` command event from the `orderCommands` topic followed by the `ContainerAllocated` and `VoyageAssigned` events that are part of the long running transaction of the [SAGA pattern](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) the `OrderCreated` events triggers.\n\n## Clean up\n\nIf you wish to cleanup your environment to the initial state where no order or container was created and your kafka topics where empty, execute the following steps from the terminal:\n\n1. Scale all the Appsody/OpenLiberty apps to 0 replicas so that there is no consumer or consumer group hooked up to any kafka topic\n\n  ```\n  for APP in $(oc get AppsodyApplication,OpenLibertyApplication | grep \"-\" | awk '{print $1}'); do oc patch $APP --type 'json' -p '[{\"op\":\"add\", \"path\":\"/spec/replicas\", \"value\":0}]'; done\n  ```\n\n1. Delete the postgresql database that stores the state of the existing containers so all those existing containers are removed\n\n  ```\n  oc delete pod/postgres-db-postgresql-0\n  ```\n\n1. Delete all kafka topics so that we get rid of all existing events in them\n\n  ```\n  for i in `oc get kafkatopics | grep '-' | awk '{print $1}'`; do oc delete kafkatopic $i; done\n  ```\n\n1. Wait until the below command returns 1. This is to ensure that all the topics have been removed (it may take a couple of minutes to the Strimzi operator to accomplish the task)\n\n  ```\n  oc exec -it my-cluster-kafka-0 -- ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092 | wc -l\n  ```\n\n1. Download the definition of the kafka topics in order to recreate these\n\n  ```\n  curl -o kafka-topics.yaml https://raw.githubusercontent.com/ibm-cloud-architecture/refarch-kc-gitops/master/environments/dev/apps/refarch-kc/base/kafka/kafka-topics.yaml\n  ```\n\n1. Recreate the kafka topics\n\n  ```\n  oc apply -f kafka-topics.yaml\n  ```\n\n1. Wait until the below command returns 10 or greater. This is to ensure that all the topics have been created (it may take a couple of minutes to the Strimzi operator to accomplish the task)\n\n  ```\n  oc exec -it my-cluster-kafka-0 -- ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092 | wc -l\n  ```\n\n1. Scale all the Appsody/OpenLiberty apps back to 1 replica\n\n  ```\n  for APP in $(oc get AppsodyApplication,OpenLibertyApplication | grep \"-\" | awk '{print $1}'); do oc patch $APP --type 'json' -p '[{\"op\":\"add\", \"path\":\"/spec/replicas\", \"value\":1}]'; done\n  ```\n\n1. You may need to wait a couple of minutes for these Appsody and OpenLiberty applications to get started. You can check the status of these running\n\n  ```\n  oc get pods -l app.kubernetes.io/part-of=refarch-kc\n  ```\n\n_This quickstart guide will be updated as the project evolves and new capability is added. If you have any issues or queries with this quickstart guide, please [raise an issue](https://github.com/ibm-cloud-architecture/refarch-kc/issues) in the github repo._\n","fileAbsolutePath":"/home/runner/work/refarch-kc/refarch-kc/docs/src/pages/quickstart-tutorial/deploy-on-ibm-openlabs.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}